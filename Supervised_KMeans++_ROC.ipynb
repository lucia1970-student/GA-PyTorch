{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia1970-student/GA-PyTorch/blob/main/Supervised_KMeans%2B%2B_ROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxu9rJzQwoBL",
        "outputId": "24160208-9fa6-4419-d50a-a469c5d28165"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCCZxwfko-1H",
        "outputId": "4eb02567-c7e3-4bd5-aedb-a0458a10a551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/cours_python/FSCI2610/projet\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/cours_python/FSCI2610/projet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k2JZFC_1o8Dy",
        "outputId": "1ce6cdf4-782c-4e29-efdc-2556a7c55be8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Group  avg_f0   avg_F1   avg_F2   avg_F3   avg_F4  mean_hnr    jitter  \\\n",
              "0     ASD  304.75   778.00  2245.60  3571.05  5081.95     10.75  1.958567   \n",
              "1     ASD  294.45   662.70  1939.90  3251.25  4775.30     12.25  1.663247   \n",
              "2     ASD  255.85   884.55  2183.50  3513.75  5111.40     12.90  1.422039   \n",
              "3     ASD  292.75   652.05  2022.60  3177.75  4634.10      8.65  1.729150   \n",
              "4     ASD  305.75   739.75  2294.25  3706.60  4807.55      8.30  2.033454   \n",
              "..    ...     ...      ...      ...      ...      ...       ...       ...   \n",
              "103    TD  255.05   858.95  2223.80  3384.55  4787.25      9.75  1.111741   \n",
              "104    TD  265.00  1022.95  2350.50  3596.25  4973.85      9.80  2.340409   \n",
              "105    TD  266.45   762.45  2278.70  3557.60  4742.95     10.95  1.489093   \n",
              "106    TD  274.95   873.00  2299.70  3672.65  4917.65      9.35  1.391963   \n",
              "107    TD  149.75  1102.55  2514.30  3747.50  5209.35      7.25  2.516211   \n",
              "\n",
              "      shimmer  dispersion_formantique  avg_f0_k  mean_hnr_k  jitter_k  \\\n",
              "0    1.377360             1434.650000  4.120596    6.512729  4.430703   \n",
              "1    1.389308             1370.866667  2.278845    3.440682  3.091686   \n",
              "2    1.185426             1408.950000  1.737850    5.391922  2.999970   \n",
              "3    1.645441             1327.350000  8.688811    2.620909  2.320086   \n",
              "4    1.544171             1355.933333  3.761873    3.485672  3.841500   \n",
              "..        ...                     ...       ...         ...       ...   \n",
              "103  1.302515             1309.433333  5.190369    3.365465  1.875519   \n",
              "104  1.299065             1316.966667  3.619754    6.548035  8.302562   \n",
              "105  1.517415             1326.833333  2.151113    2.531716  3.208905   \n",
              "106  1.264749             1348.216667  3.473041    2.755562  2.825725   \n",
              "107  1.570721             1368.933333  3.456351    5.940674  2.695571   \n",
              "\n",
              "     shimmer_k  dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s  \\\n",
              "0     2.066858                  5.193159  1.026296    1.519206  1.205160   \n",
              "1     3.108758                  2.927942  0.133170    0.667077  0.560049   \n",
              "2     3.019235                  2.481138  0.169958    1.548892  0.722608   \n",
              "3     2.652073                  2.249446 -2.098723   -0.134290  0.045519   \n",
              "4     7.036189                  3.318189  0.993320    0.670789  1.151768   \n",
              "..         ...                       ...       ...         ...       ...   \n",
              "103   3.242620                  1.881098  1.338850    0.806779  0.273689   \n",
              "104   2.789693                  4.012588  1.028263    1.752227  2.363517   \n",
              "105   2.385634                  3.771958  0.114164    0.130736  0.951328   \n",
              "106   2.361107                  2.442094 -0.777756    0.412494  0.655506   \n",
              "107   2.150739                  2.009205  1.171288    1.303329  0.610251   \n",
              "\n",
              "     shimmer_s  dispersion_formantique_s  \n",
              "0    -0.259522                  0.069057  \n",
              "1    -0.244830                 -0.390032  \n",
              "2    -0.348192                  0.175821  \n",
              "3     0.452664                  0.225971  \n",
              "4    -1.606129                 -0.338201  \n",
              "..         ...                       ...  \n",
              "103  -0.246472                  0.152368  \n",
              "104   0.612808                  0.451664  \n",
              "105  -0.507807                  1.004282  \n",
              "106   0.554750                 -0.074498  \n",
              "107   0.011729                  0.064346  \n",
              "\n",
              "[108 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1e71a73-b893-44a6-84a4-f17680bc2945\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Group</th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ASD</td>\n",
              "      <td>304.75</td>\n",
              "      <td>778.00</td>\n",
              "      <td>2245.60</td>\n",
              "      <td>3571.05</td>\n",
              "      <td>5081.95</td>\n",
              "      <td>10.75</td>\n",
              "      <td>1.958567</td>\n",
              "      <td>1.377360</td>\n",
              "      <td>1434.650000</td>\n",
              "      <td>4.120596</td>\n",
              "      <td>6.512729</td>\n",
              "      <td>4.430703</td>\n",
              "      <td>2.066858</td>\n",
              "      <td>5.193159</td>\n",
              "      <td>1.026296</td>\n",
              "      <td>1.519206</td>\n",
              "      <td>1.205160</td>\n",
              "      <td>-0.259522</td>\n",
              "      <td>0.069057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ASD</td>\n",
              "      <td>294.45</td>\n",
              "      <td>662.70</td>\n",
              "      <td>1939.90</td>\n",
              "      <td>3251.25</td>\n",
              "      <td>4775.30</td>\n",
              "      <td>12.25</td>\n",
              "      <td>1.663247</td>\n",
              "      <td>1.389308</td>\n",
              "      <td>1370.866667</td>\n",
              "      <td>2.278845</td>\n",
              "      <td>3.440682</td>\n",
              "      <td>3.091686</td>\n",
              "      <td>3.108758</td>\n",
              "      <td>2.927942</td>\n",
              "      <td>0.133170</td>\n",
              "      <td>0.667077</td>\n",
              "      <td>0.560049</td>\n",
              "      <td>-0.244830</td>\n",
              "      <td>-0.390032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ASD</td>\n",
              "      <td>255.85</td>\n",
              "      <td>884.55</td>\n",
              "      <td>2183.50</td>\n",
              "      <td>3513.75</td>\n",
              "      <td>5111.40</td>\n",
              "      <td>12.90</td>\n",
              "      <td>1.422039</td>\n",
              "      <td>1.185426</td>\n",
              "      <td>1408.950000</td>\n",
              "      <td>1.737850</td>\n",
              "      <td>5.391922</td>\n",
              "      <td>2.999970</td>\n",
              "      <td>3.019235</td>\n",
              "      <td>2.481138</td>\n",
              "      <td>0.169958</td>\n",
              "      <td>1.548892</td>\n",
              "      <td>0.722608</td>\n",
              "      <td>-0.348192</td>\n",
              "      <td>0.175821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ASD</td>\n",
              "      <td>292.75</td>\n",
              "      <td>652.05</td>\n",
              "      <td>2022.60</td>\n",
              "      <td>3177.75</td>\n",
              "      <td>4634.10</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.729150</td>\n",
              "      <td>1.645441</td>\n",
              "      <td>1327.350000</td>\n",
              "      <td>8.688811</td>\n",
              "      <td>2.620909</td>\n",
              "      <td>2.320086</td>\n",
              "      <td>2.652073</td>\n",
              "      <td>2.249446</td>\n",
              "      <td>-2.098723</td>\n",
              "      <td>-0.134290</td>\n",
              "      <td>0.045519</td>\n",
              "      <td>0.452664</td>\n",
              "      <td>0.225971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ASD</td>\n",
              "      <td>305.75</td>\n",
              "      <td>739.75</td>\n",
              "      <td>2294.25</td>\n",
              "      <td>3706.60</td>\n",
              "      <td>4807.55</td>\n",
              "      <td>8.30</td>\n",
              "      <td>2.033454</td>\n",
              "      <td>1.544171</td>\n",
              "      <td>1355.933333</td>\n",
              "      <td>3.761873</td>\n",
              "      <td>3.485672</td>\n",
              "      <td>3.841500</td>\n",
              "      <td>7.036189</td>\n",
              "      <td>3.318189</td>\n",
              "      <td>0.993320</td>\n",
              "      <td>0.670789</td>\n",
              "      <td>1.151768</td>\n",
              "      <td>-1.606129</td>\n",
              "      <td>-0.338201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>TD</td>\n",
              "      <td>255.05</td>\n",
              "      <td>858.95</td>\n",
              "      <td>2223.80</td>\n",
              "      <td>3384.55</td>\n",
              "      <td>4787.25</td>\n",
              "      <td>9.75</td>\n",
              "      <td>1.111741</td>\n",
              "      <td>1.302515</td>\n",
              "      <td>1309.433333</td>\n",
              "      <td>5.190369</td>\n",
              "      <td>3.365465</td>\n",
              "      <td>1.875519</td>\n",
              "      <td>3.242620</td>\n",
              "      <td>1.881098</td>\n",
              "      <td>1.338850</td>\n",
              "      <td>0.806779</td>\n",
              "      <td>0.273689</td>\n",
              "      <td>-0.246472</td>\n",
              "      <td>0.152368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>TD</td>\n",
              "      <td>265.00</td>\n",
              "      <td>1022.95</td>\n",
              "      <td>2350.50</td>\n",
              "      <td>3596.25</td>\n",
              "      <td>4973.85</td>\n",
              "      <td>9.80</td>\n",
              "      <td>2.340409</td>\n",
              "      <td>1.299065</td>\n",
              "      <td>1316.966667</td>\n",
              "      <td>3.619754</td>\n",
              "      <td>6.548035</td>\n",
              "      <td>8.302562</td>\n",
              "      <td>2.789693</td>\n",
              "      <td>4.012588</td>\n",
              "      <td>1.028263</td>\n",
              "      <td>1.752227</td>\n",
              "      <td>2.363517</td>\n",
              "      <td>0.612808</td>\n",
              "      <td>0.451664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>TD</td>\n",
              "      <td>266.45</td>\n",
              "      <td>762.45</td>\n",
              "      <td>2278.70</td>\n",
              "      <td>3557.60</td>\n",
              "      <td>4742.95</td>\n",
              "      <td>10.95</td>\n",
              "      <td>1.489093</td>\n",
              "      <td>1.517415</td>\n",
              "      <td>1326.833333</td>\n",
              "      <td>2.151113</td>\n",
              "      <td>2.531716</td>\n",
              "      <td>3.208905</td>\n",
              "      <td>2.385634</td>\n",
              "      <td>3.771958</td>\n",
              "      <td>0.114164</td>\n",
              "      <td>0.130736</td>\n",
              "      <td>0.951328</td>\n",
              "      <td>-0.507807</td>\n",
              "      <td>1.004282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>TD</td>\n",
              "      <td>274.95</td>\n",
              "      <td>873.00</td>\n",
              "      <td>2299.70</td>\n",
              "      <td>3672.65</td>\n",
              "      <td>4917.65</td>\n",
              "      <td>9.35</td>\n",
              "      <td>1.391963</td>\n",
              "      <td>1.264749</td>\n",
              "      <td>1348.216667</td>\n",
              "      <td>3.473041</td>\n",
              "      <td>2.755562</td>\n",
              "      <td>2.825725</td>\n",
              "      <td>2.361107</td>\n",
              "      <td>2.442094</td>\n",
              "      <td>-0.777756</td>\n",
              "      <td>0.412494</td>\n",
              "      <td>0.655506</td>\n",
              "      <td>0.554750</td>\n",
              "      <td>-0.074498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>TD</td>\n",
              "      <td>149.75</td>\n",
              "      <td>1102.55</td>\n",
              "      <td>2514.30</td>\n",
              "      <td>3747.50</td>\n",
              "      <td>5209.35</td>\n",
              "      <td>7.25</td>\n",
              "      <td>2.516211</td>\n",
              "      <td>1.570721</td>\n",
              "      <td>1368.933333</td>\n",
              "      <td>3.456351</td>\n",
              "      <td>5.940674</td>\n",
              "      <td>2.695571</td>\n",
              "      <td>2.150739</td>\n",
              "      <td>2.009205</td>\n",
              "      <td>1.171288</td>\n",
              "      <td>1.303329</td>\n",
              "      <td>0.610251</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.064346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows Ã— 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1e71a73-b893-44a6-84a4-f17680bc2945')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1e71a73-b893-44a6-84a4-f17680bc2945 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1e71a73-b893-44a6-84a4-f17680bc2945');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-826d1cee-cd13-4012-bc28-db806ff97cd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-826d1cee-cd13-4012-bc28-db806ff97cd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-826d1cee-cd13-4012-bc28-db806ff97cd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d5e84070-dee3-4870-8039-9f6205d3cb6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d5e84070-dee3-4870-8039-9f6205d3cb6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 108,\n  \"fields\": [\n    {\n      \"column\": \"Group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SLI\",\n          \"TD\",\n          \"ASD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.16771777220911,\n        \"min\": 135.35,\n        \"max\": 350.85,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          215.35,\n          242.35,\n          305.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.99713570968208,\n        \"min\": 568.1,\n        \"max\": 1265.75,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          719.1,\n          568.1,\n          739.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 136.47788514342105,\n        \"min\": 1938.95,\n        \"max\": 2633.3,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2259.5,\n          2164.15,\n          2294.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139.67710633553338,\n        \"min\": 3177.75,\n        \"max\": 3970.9,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3417.8,\n          3594.7,\n          3706.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.18893719350055,\n        \"min\": 4581.1,\n        \"max\": 5302.25,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          4635.85,\n          4882.15,\n          4807.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4089801040933527,\n        \"min\": 4.9,\n        \"max\": 16.55,\n        \"num_unique_values\": 86,\n        \"samples\": [\n          7.7,\n          10.75,\n          8.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4010864360120488,\n        \"min\": 0.735873708,\n        \"max\": 3.024994612,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.195084014,\n          1.274712822,\n          2.033453727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19359601392765116,\n        \"min\": 0.816624405,\n        \"max\": 1.842686333,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.223120187,\n          1.428855234,\n          1.544170528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.44555455156344,\n        \"min\": 1159.033333,\n        \"max\": 1506.983333,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1305.583333,\n          1438.016667,\n          1355.933333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.268528561677701,\n        \"min\": 1.502538523,\n        \"max\": 14.22461757,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3.027195528,\n          3.649101316,\n          3.761873329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0840278158327785,\n        \"min\": 1.636628881,\n        \"max\": 6.548035431,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.509274249,\n          1.789300412,\n          3.485671715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.705186649411072,\n        \"min\": 1.708948397,\n        \"max\": 13.88318885,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          4.154415567,\n          2.814530876,\n          3.841500406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.323388126187469,\n        \"min\": 1.834133086,\n        \"max\": 9.666449675,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.09295084,\n          3.457993601,\n          7.036189341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7051505343774105,\n        \"min\": 1.632534979,\n        \"max\": 5.19315907,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.704034183,\n          4.223795797,\n          3.31818879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.022456312380928,\n        \"min\": -2.734113835,\n        \"max\": 3.425743983,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          -0.265908939,\n          0.898138225,\n          0.993319641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5506275552762182,\n        \"min\": -0.669774925,\n        \"max\": 1.761441582,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          0.115366857,\n          -0.163299316,\n          0.670789359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8102158693374696,\n        \"min\": -0.439475583,\n        \"max\": 3.303385805,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.193736424,\n          0.562025818,\n          1.151768479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6605966932303408,\n        \"min\": -1.606129365,\n        \"max\": 2.336159712,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          -0.121888845,\n          -0.154744973,\n          -1.606129365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4935783028237649,\n        \"min\": -1.157513779,\n        \"max\": 1.126439929,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          0.387588852,\n          -0.122836266,\n          -0.338201178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['Group', 'avg_f0', 'avg_F1', 'avg_F2', 'avg_F3', 'avg_F4', 'mean_hnr',\n",
              "       'jitter', 'shimmer', 'dispersion_formantique', 'avg_f0_k', 'mean_hnr_k',\n",
              "       'jitter_k', 'shimmer_k', 'dispersion_formantique_k', 'avg_f0_s',\n",
              "       'mean_hnr_s', 'jitter_s', 'shimmer_s', 'dispersion_formantique_s'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTRL count without TD (24):  70\n",
            "ASD count:  38\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Group  avg_f0  avg_F1   avg_F2   avg_F3   avg_F4   mean_hnr  jitter    shimmer   dispersion_formantique  avg_f0_k  mean_hnr_k  jitter_k  shimmer_k  dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s   shimmer_s  dispersion_formantique_s\n",
              "ASD    135.35  988.15   2393.45  3640.05  4875.60  4.90      1.490435  1.602262  1295.816667             7.724096  3.591570    5.565571  7.160721   1.632535                  2.314049   0.899021    1.875244   2.080483   0.021249                   1\n",
              "SLI    267.15  950.75   2354.50  3420.55  4681.85  9.80      1.222840  1.100797  1243.700000             3.163465  2.026336    2.003743  2.851964   2.089819                  0.824082   0.472550    0.358002   0.339679  -0.061841                   1\n",
              "       300.80  769.60   2079.05  3331.15  4790.55  14.15     0.790875  1.102135  1340.316667             3.220332  2.145983    2.468427  2.772546   3.880961                  1.094163   0.190177    0.845510   0.510875   0.261225                   1\n",
              "       300.30  1001.35  2518.35  3970.90  5302.25  13.30     1.498298  1.501590  1433.633333             3.677679  2.536378    4.656360  5.951269   3.461849                  0.711598   0.362425    1.380237   0.763329   0.567253                   1\n",
              "       291.35  1029.95  2440.60  3591.35  4955.00  10.15     1.155211  1.010466  1308.350000             6.415412  6.520670    2.538592  2.137952   2.184312                  1.744851   1.761442    0.915314   0.059145   0.006798                   1\n",
              "                                                                                                                                                                                                                                                     ..\n",
              "ASD    335.30  668.75   2005.45  3214.50  4607.80  9.60      1.705673  1.562046  1313.016667             3.668807  3.216171    2.332092  3.348500   2.970892                  0.467641   0.735932    0.271600  -0.835370  -0.251010                   1\n",
              "       334.10  684.90   2094.30  3579.70  4856.10  11.30     2.190127  1.458687  1390.400000             3.270168  2.770940    2.156335  2.384491   3.616185                  0.073779   0.540132   -0.271603  -0.347822   0.721927                   1\n",
              "       331.95  779.30   2271.30  3687.00  4806.70  9.30      1.989887  1.514565  1342.466667             3.788538  2.111079    3.193975  3.715863   2.814807                  0.336245  -0.508081    0.757273   1.094934   0.379331                   1\n",
              "       325.80  773.75   2243.80  3530.95  4862.85  8.50      2.070477  1.697217  1363.033333             8.262409  2.766723    2.527389  2.369298   2.733893                  2.055750  -0.081247    0.729531  -0.299465   0.665008                   1\n",
              "TD     319.55  1073.60  2495.70  3786.50  4988.30  7.70      1.153545  1.174254  1304.900000             2.853541  2.986775    4.395455  2.258666   2.654484                  0.807288  -0.228113    1.250874   0.182217   0.282963                   1\n",
              "Name: count, Length: 108, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Group</th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ASD</th>\n",
              "      <th>135.35</th>\n",
              "      <th>988.15</th>\n",
              "      <th>2393.45</th>\n",
              "      <th>3640.05</th>\n",
              "      <th>4875.60</th>\n",
              "      <th>4.90</th>\n",
              "      <th>1.490435</th>\n",
              "      <th>1.602262</th>\n",
              "      <th>1295.816667</th>\n",
              "      <th>7.724096</th>\n",
              "      <th>3.591570</th>\n",
              "      <th>5.565571</th>\n",
              "      <th>7.160721</th>\n",
              "      <th>1.632535</th>\n",
              "      <th>2.314049</th>\n",
              "      <th>0.899021</th>\n",
              "      <th>1.875244</th>\n",
              "      <th>2.080483</th>\n",
              "      <th>0.021249</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">SLI</th>\n",
              "      <th>267.15</th>\n",
              "      <th>950.75</th>\n",
              "      <th>2354.50</th>\n",
              "      <th>3420.55</th>\n",
              "      <th>4681.85</th>\n",
              "      <th>9.80</th>\n",
              "      <th>1.222840</th>\n",
              "      <th>1.100797</th>\n",
              "      <th>1243.700000</th>\n",
              "      <th>3.163465</th>\n",
              "      <th>2.026336</th>\n",
              "      <th>2.003743</th>\n",
              "      <th>2.851964</th>\n",
              "      <th>2.089819</th>\n",
              "      <th>0.824082</th>\n",
              "      <th>0.472550</th>\n",
              "      <th>0.358002</th>\n",
              "      <th>0.339679</th>\n",
              "      <th>-0.061841</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300.80</th>\n",
              "      <th>769.60</th>\n",
              "      <th>2079.05</th>\n",
              "      <th>3331.15</th>\n",
              "      <th>4790.55</th>\n",
              "      <th>14.15</th>\n",
              "      <th>0.790875</th>\n",
              "      <th>1.102135</th>\n",
              "      <th>1340.316667</th>\n",
              "      <th>3.220332</th>\n",
              "      <th>2.145983</th>\n",
              "      <th>2.468427</th>\n",
              "      <th>2.772546</th>\n",
              "      <th>3.880961</th>\n",
              "      <th>1.094163</th>\n",
              "      <th>0.190177</th>\n",
              "      <th>0.845510</th>\n",
              "      <th>0.510875</th>\n",
              "      <th>0.261225</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300.30</th>\n",
              "      <th>1001.35</th>\n",
              "      <th>2518.35</th>\n",
              "      <th>3970.90</th>\n",
              "      <th>5302.25</th>\n",
              "      <th>13.30</th>\n",
              "      <th>1.498298</th>\n",
              "      <th>1.501590</th>\n",
              "      <th>1433.633333</th>\n",
              "      <th>3.677679</th>\n",
              "      <th>2.536378</th>\n",
              "      <th>4.656360</th>\n",
              "      <th>5.951269</th>\n",
              "      <th>3.461849</th>\n",
              "      <th>0.711598</th>\n",
              "      <th>0.362425</th>\n",
              "      <th>1.380237</th>\n",
              "      <th>0.763329</th>\n",
              "      <th>0.567253</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291.35</th>\n",
              "      <th>1029.95</th>\n",
              "      <th>2440.60</th>\n",
              "      <th>3591.35</th>\n",
              "      <th>4955.00</th>\n",
              "      <th>10.15</th>\n",
              "      <th>1.155211</th>\n",
              "      <th>1.010466</th>\n",
              "      <th>1308.350000</th>\n",
              "      <th>6.415412</th>\n",
              "      <th>6.520670</th>\n",
              "      <th>2.538592</th>\n",
              "      <th>2.137952</th>\n",
              "      <th>2.184312</th>\n",
              "      <th>1.744851</th>\n",
              "      <th>1.761442</th>\n",
              "      <th>0.915314</th>\n",
              "      <th>0.059145</th>\n",
              "      <th>0.006798</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ASD</th>\n",
              "      <th>335.30</th>\n",
              "      <th>668.75</th>\n",
              "      <th>2005.45</th>\n",
              "      <th>3214.50</th>\n",
              "      <th>4607.80</th>\n",
              "      <th>9.60</th>\n",
              "      <th>1.705673</th>\n",
              "      <th>1.562046</th>\n",
              "      <th>1313.016667</th>\n",
              "      <th>3.668807</th>\n",
              "      <th>3.216171</th>\n",
              "      <th>2.332092</th>\n",
              "      <th>3.348500</th>\n",
              "      <th>2.970892</th>\n",
              "      <th>0.467641</th>\n",
              "      <th>0.735932</th>\n",
              "      <th>0.271600</th>\n",
              "      <th>-0.835370</th>\n",
              "      <th>-0.251010</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334.10</th>\n",
              "      <th>684.90</th>\n",
              "      <th>2094.30</th>\n",
              "      <th>3579.70</th>\n",
              "      <th>4856.10</th>\n",
              "      <th>11.30</th>\n",
              "      <th>2.190127</th>\n",
              "      <th>1.458687</th>\n",
              "      <th>1390.400000</th>\n",
              "      <th>3.270168</th>\n",
              "      <th>2.770940</th>\n",
              "      <th>2.156335</th>\n",
              "      <th>2.384491</th>\n",
              "      <th>3.616185</th>\n",
              "      <th>0.073779</th>\n",
              "      <th>0.540132</th>\n",
              "      <th>-0.271603</th>\n",
              "      <th>-0.347822</th>\n",
              "      <th>0.721927</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331.95</th>\n",
              "      <th>779.30</th>\n",
              "      <th>2271.30</th>\n",
              "      <th>3687.00</th>\n",
              "      <th>4806.70</th>\n",
              "      <th>9.30</th>\n",
              "      <th>1.989887</th>\n",
              "      <th>1.514565</th>\n",
              "      <th>1342.466667</th>\n",
              "      <th>3.788538</th>\n",
              "      <th>2.111079</th>\n",
              "      <th>3.193975</th>\n",
              "      <th>3.715863</th>\n",
              "      <th>2.814807</th>\n",
              "      <th>0.336245</th>\n",
              "      <th>-0.508081</th>\n",
              "      <th>0.757273</th>\n",
              "      <th>1.094934</th>\n",
              "      <th>0.379331</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325.80</th>\n",
              "      <th>773.75</th>\n",
              "      <th>2243.80</th>\n",
              "      <th>3530.95</th>\n",
              "      <th>4862.85</th>\n",
              "      <th>8.50</th>\n",
              "      <th>2.070477</th>\n",
              "      <th>1.697217</th>\n",
              "      <th>1363.033333</th>\n",
              "      <th>8.262409</th>\n",
              "      <th>2.766723</th>\n",
              "      <th>2.527389</th>\n",
              "      <th>2.369298</th>\n",
              "      <th>2.733893</th>\n",
              "      <th>2.055750</th>\n",
              "      <th>-0.081247</th>\n",
              "      <th>0.729531</th>\n",
              "      <th>-0.299465</th>\n",
              "      <th>0.665008</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TD</th>\n",
              "      <th>319.55</th>\n",
              "      <th>1073.60</th>\n",
              "      <th>2495.70</th>\n",
              "      <th>3786.50</th>\n",
              "      <th>4988.30</th>\n",
              "      <th>7.70</th>\n",
              "      <th>1.153545</th>\n",
              "      <th>1.174254</th>\n",
              "      <th>1304.900000</th>\n",
              "      <th>2.853541</th>\n",
              "      <th>2.986775</th>\n",
              "      <th>4.395455</th>\n",
              "      <th>2.258666</th>\n",
              "      <th>2.654484</th>\n",
              "      <th>0.807288</th>\n",
              "      <th>-0.228113</th>\n",
              "      <th>1.250874</th>\n",
              "      <th>0.182217</th>\n",
              "      <th>0.282963</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Autism prognosis using voice biomarkers.\n",
        "\n",
        "#Dataset from study below.  Available on request.\n",
        "# https://www.nature.com/articles/s41398-023-02554-8#Fig2\n",
        "\n",
        "#I am proposing ALL characteristics of voice biomarkers (19) and 2 target\n",
        "#classes (CTRL (no TD) and ASD) in order to classify data.\n",
        "#The purpose of this iteration is to validate the study results.\n",
        "#The validation steps are detailed below:\n",
        "\n",
        "#1. Selecting ALL characteristicss and 2 classes ('ASD' and 'TD') as per study's\n",
        "#identified characteristics and classes.  The 19 characteristics have been ranked\n",
        "# with Recursive Feature Elimination (RFE).  No characteristics were eliminated at\n",
        "# this stage.\n",
        "\n",
        "#2. Applied feature rankings and applied  dimension reduction with RFE and PCA.\n",
        "# PCA components = 4 @ 99% coverage.  84 rows out 108, no rows were eliminated.\n",
        "\n",
        "#3. Split dataset into train/test (70%/30%) with StratifiedShuffleSplit and ran\n",
        "#multiple randomized folds of KMeans++ with k=2 while mapping clustering_labels\n",
        "#to actual values (Ground Truth) for each and finally computing ROC_AUC score\n",
        "# on the mapped results.  Many metrics for each foldis being shown.\n",
        "\n",
        "#4 Ploted the average ROC_AUC curve and plotted the confusion matrix.\n",
        "\n",
        "#5. As comparison, I have applied a ShuffleSplit cross-validation of SVC.\n",
        "#and displayed performance results.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#Load data.\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"voice_data.csv\")\n",
        "data=df.copy()\n",
        "display.max_columns = None\n",
        "display.nax_rows = None\n",
        "display(data)\n",
        "display(data.columns)\n",
        "\n",
        "a = np.count_nonzero(data.Group == 'TD')\n",
        "b = td_count = np.count_nonzero(data.Group == 'IC')\n",
        "c = td_count = np.count_nonzero(data.Group == 'SLI')\n",
        "d = np.count_nonzero(data.Group == 'ASD')\n",
        "z = a + b + c\n",
        "print('CTRL count without TD (24): ', z)\n",
        "print('ASD count: ', d)\n",
        "display(data.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "# Fit the LabelEncoder to the 'Group' column and transform it\n",
        "\n",
        "df = df[df['Group'] != 'TD']  # Keep rows where 'Group' is not 'TD'\n",
        "df['Group_Encoded'] = le.fit_transform(df['Group'])\n",
        "\n",
        "y = df['Group_Encoded'].values\n",
        "df.drop('Group_Encoded', axis=1, inplace =True)\n",
        "X = df.iloc[:,1:]  # Assuming you want the second column of df\n",
        "\n",
        "#print('\\nX: \\n', X)\n",
        "\n",
        "for i in range(len(y)) :\n",
        "  if y[i] != 1:\n",
        "    y[i] = 0\n",
        "print('\\ny: ', y)\n",
        "display(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "hwm_sxeNgBoj",
        "outputId": "3f68d6bd-bbf3-49e2-977a-c17ca89a6464"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "y:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    avg_f0   avg_F1   avg_F2   avg_F3   avg_F4  mean_hnr    jitter   shimmer  \\\n",
              "0   304.75   778.00  2245.60  3571.05  5081.95     10.75  1.958567  1.377360   \n",
              "1   294.45   662.70  1939.90  3251.25  4775.30     12.25  1.663247  1.389308   \n",
              "2   255.85   884.55  2183.50  3513.75  5111.40     12.90  1.422039  1.185426   \n",
              "3   292.75   652.05  2022.60  3177.75  4634.10      8.65  1.729150  1.645441   \n",
              "4   305.75   739.75  2294.25  3706.60  4807.55      8.30  2.033454  1.544171   \n",
              "..     ...      ...      ...      ...      ...       ...       ...       ...   \n",
              "79  272.40  1048.20  2396.10  3607.90  4777.30      8.65  1.148303  1.353881   \n",
              "80  301.10   782.05  2184.90  3415.10  4666.85     11.00  1.254625  0.952392   \n",
              "81  286.40   771.40  2272.80  3570.15  5088.50     10.35  1.583144  1.138822   \n",
              "82  261.35   682.65  2352.25  3547.65  5095.75     12.10  1.463657  1.052067   \n",
              "83  238.55  1020.15  2396.90  3565.35  4919.50      8.90  1.346442  1.266389   \n",
              "\n",
              "    dispersion_formantique   avg_f0_k  mean_hnr_k  jitter_k  shimmer_k  \\\n",
              "0              1434.650000   4.120596    6.512729  4.430703   2.066858   \n",
              "1              1370.866667   2.278845    3.440682  3.091686   3.108758   \n",
              "2              1408.950000   1.737850    5.391922  2.999970   3.019235   \n",
              "3              1327.350000   8.688811    2.620909  2.320086   2.652073   \n",
              "4              1355.933333   3.761873    3.485672  3.841500   7.036189   \n",
              "..                     ...        ...         ...       ...        ...   \n",
              "79             1243.033333   2.016973    2.138940  2.361210   3.209799   \n",
              "80             1294.933333  11.621063    2.995300  2.293056   2.490964   \n",
              "81             1439.033333   1.879826    4.383631  8.614788   2.707580   \n",
              "82             1471.033333   2.322844    1.838558  2.875774   1.973561   \n",
              "83             1299.783333   4.507005    2.386358  7.583330   2.475709   \n",
              "\n",
              "    dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s  shimmer_s  \\\n",
              "0                   5.193159  1.026296    1.519206  1.205160  -0.259522   \n",
              "1                   2.927942  0.133170    0.667077  0.560049  -0.244830   \n",
              "2                   2.481138  0.169958    1.548892  0.722608  -0.348192   \n",
              "3                   2.249446 -2.098723   -0.134290  0.045519   0.452664   \n",
              "4                   3.318189  0.993320    0.670789  1.151768  -1.606129   \n",
              "..                       ...       ...         ...       ...        ...   \n",
              "79                  2.195920 -0.675089   -0.074399  0.689445  -0.774658   \n",
              "80                  2.263339 -2.734114   -0.011581  0.444379   0.013398   \n",
              "81                  1.990779 -0.242029    1.170294  2.336884   0.309732   \n",
              "82                  2.330892  0.462941    0.378098  0.655235   0.279183   \n",
              "83                  1.914359 -1.598119    0.170505  2.139388   0.003517   \n",
              "\n",
              "    dispersion_formantique_s  \n",
              "0                   0.069057  \n",
              "1                  -0.390032  \n",
              "2                   0.175821  \n",
              "3                   0.225971  \n",
              "4                  -0.338201  \n",
              "..                       ...  \n",
              "79                 -0.183286  \n",
              "80                 -0.097667  \n",
              "81                  0.185251  \n",
              "82                 -0.266588  \n",
              "83                  0.038005  \n",
              "\n",
              "[84 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d3a9b4d-f931-41a1-a685-22084e5c5cf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>304.75</td>\n",
              "      <td>778.00</td>\n",
              "      <td>2245.60</td>\n",
              "      <td>3571.05</td>\n",
              "      <td>5081.95</td>\n",
              "      <td>10.75</td>\n",
              "      <td>1.958567</td>\n",
              "      <td>1.377360</td>\n",
              "      <td>1434.650000</td>\n",
              "      <td>4.120596</td>\n",
              "      <td>6.512729</td>\n",
              "      <td>4.430703</td>\n",
              "      <td>2.066858</td>\n",
              "      <td>5.193159</td>\n",
              "      <td>1.026296</td>\n",
              "      <td>1.519206</td>\n",
              "      <td>1.205160</td>\n",
              "      <td>-0.259522</td>\n",
              "      <td>0.069057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>294.45</td>\n",
              "      <td>662.70</td>\n",
              "      <td>1939.90</td>\n",
              "      <td>3251.25</td>\n",
              "      <td>4775.30</td>\n",
              "      <td>12.25</td>\n",
              "      <td>1.663247</td>\n",
              "      <td>1.389308</td>\n",
              "      <td>1370.866667</td>\n",
              "      <td>2.278845</td>\n",
              "      <td>3.440682</td>\n",
              "      <td>3.091686</td>\n",
              "      <td>3.108758</td>\n",
              "      <td>2.927942</td>\n",
              "      <td>0.133170</td>\n",
              "      <td>0.667077</td>\n",
              "      <td>0.560049</td>\n",
              "      <td>-0.244830</td>\n",
              "      <td>-0.390032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>255.85</td>\n",
              "      <td>884.55</td>\n",
              "      <td>2183.50</td>\n",
              "      <td>3513.75</td>\n",
              "      <td>5111.40</td>\n",
              "      <td>12.90</td>\n",
              "      <td>1.422039</td>\n",
              "      <td>1.185426</td>\n",
              "      <td>1408.950000</td>\n",
              "      <td>1.737850</td>\n",
              "      <td>5.391922</td>\n",
              "      <td>2.999970</td>\n",
              "      <td>3.019235</td>\n",
              "      <td>2.481138</td>\n",
              "      <td>0.169958</td>\n",
              "      <td>1.548892</td>\n",
              "      <td>0.722608</td>\n",
              "      <td>-0.348192</td>\n",
              "      <td>0.175821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>292.75</td>\n",
              "      <td>652.05</td>\n",
              "      <td>2022.60</td>\n",
              "      <td>3177.75</td>\n",
              "      <td>4634.10</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.729150</td>\n",
              "      <td>1.645441</td>\n",
              "      <td>1327.350000</td>\n",
              "      <td>8.688811</td>\n",
              "      <td>2.620909</td>\n",
              "      <td>2.320086</td>\n",
              "      <td>2.652073</td>\n",
              "      <td>2.249446</td>\n",
              "      <td>-2.098723</td>\n",
              "      <td>-0.134290</td>\n",
              "      <td>0.045519</td>\n",
              "      <td>0.452664</td>\n",
              "      <td>0.225971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>305.75</td>\n",
              "      <td>739.75</td>\n",
              "      <td>2294.25</td>\n",
              "      <td>3706.60</td>\n",
              "      <td>4807.55</td>\n",
              "      <td>8.30</td>\n",
              "      <td>2.033454</td>\n",
              "      <td>1.544171</td>\n",
              "      <td>1355.933333</td>\n",
              "      <td>3.761873</td>\n",
              "      <td>3.485672</td>\n",
              "      <td>3.841500</td>\n",
              "      <td>7.036189</td>\n",
              "      <td>3.318189</td>\n",
              "      <td>0.993320</td>\n",
              "      <td>0.670789</td>\n",
              "      <td>1.151768</td>\n",
              "      <td>-1.606129</td>\n",
              "      <td>-0.338201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>272.40</td>\n",
              "      <td>1048.20</td>\n",
              "      <td>2396.10</td>\n",
              "      <td>3607.90</td>\n",
              "      <td>4777.30</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.148303</td>\n",
              "      <td>1.353881</td>\n",
              "      <td>1243.033333</td>\n",
              "      <td>2.016973</td>\n",
              "      <td>2.138940</td>\n",
              "      <td>2.361210</td>\n",
              "      <td>3.209799</td>\n",
              "      <td>2.195920</td>\n",
              "      <td>-0.675089</td>\n",
              "      <td>-0.074399</td>\n",
              "      <td>0.689445</td>\n",
              "      <td>-0.774658</td>\n",
              "      <td>-0.183286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>301.10</td>\n",
              "      <td>782.05</td>\n",
              "      <td>2184.90</td>\n",
              "      <td>3415.10</td>\n",
              "      <td>4666.85</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1.254625</td>\n",
              "      <td>0.952392</td>\n",
              "      <td>1294.933333</td>\n",
              "      <td>11.621063</td>\n",
              "      <td>2.995300</td>\n",
              "      <td>2.293056</td>\n",
              "      <td>2.490964</td>\n",
              "      <td>2.263339</td>\n",
              "      <td>-2.734114</td>\n",
              "      <td>-0.011581</td>\n",
              "      <td>0.444379</td>\n",
              "      <td>0.013398</td>\n",
              "      <td>-0.097667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>286.40</td>\n",
              "      <td>771.40</td>\n",
              "      <td>2272.80</td>\n",
              "      <td>3570.15</td>\n",
              "      <td>5088.50</td>\n",
              "      <td>10.35</td>\n",
              "      <td>1.583144</td>\n",
              "      <td>1.138822</td>\n",
              "      <td>1439.033333</td>\n",
              "      <td>1.879826</td>\n",
              "      <td>4.383631</td>\n",
              "      <td>8.614788</td>\n",
              "      <td>2.707580</td>\n",
              "      <td>1.990779</td>\n",
              "      <td>-0.242029</td>\n",
              "      <td>1.170294</td>\n",
              "      <td>2.336884</td>\n",
              "      <td>0.309732</td>\n",
              "      <td>0.185251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>261.35</td>\n",
              "      <td>682.65</td>\n",
              "      <td>2352.25</td>\n",
              "      <td>3547.65</td>\n",
              "      <td>5095.75</td>\n",
              "      <td>12.10</td>\n",
              "      <td>1.463657</td>\n",
              "      <td>1.052067</td>\n",
              "      <td>1471.033333</td>\n",
              "      <td>2.322844</td>\n",
              "      <td>1.838558</td>\n",
              "      <td>2.875774</td>\n",
              "      <td>1.973561</td>\n",
              "      <td>2.330892</td>\n",
              "      <td>0.462941</td>\n",
              "      <td>0.378098</td>\n",
              "      <td>0.655235</td>\n",
              "      <td>0.279183</td>\n",
              "      <td>-0.266588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>238.55</td>\n",
              "      <td>1020.15</td>\n",
              "      <td>2396.90</td>\n",
              "      <td>3565.35</td>\n",
              "      <td>4919.50</td>\n",
              "      <td>8.90</td>\n",
              "      <td>1.346442</td>\n",
              "      <td>1.266389</td>\n",
              "      <td>1299.783333</td>\n",
              "      <td>4.507005</td>\n",
              "      <td>2.386358</td>\n",
              "      <td>7.583330</td>\n",
              "      <td>2.475709</td>\n",
              "      <td>1.914359</td>\n",
              "      <td>-1.598119</td>\n",
              "      <td>0.170505</td>\n",
              "      <td>2.139388</td>\n",
              "      <td>0.003517</td>\n",
              "      <td>0.038005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d3a9b4d-f931-41a1-a685-22084e5c5cf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d3a9b4d-f931-41a1-a685-22084e5c5cf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d3a9b4d-f931-41a1-a685-22084e5c5cf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2c0883c-ddfc-4b50-9aa9-3ffa9eaf3c70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2c0883c-ddfc-4b50-9aa9-3ffa9eaf3c70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2c0883c-ddfc-4b50-9aa9-3ffa9eaf3c70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3e5dc8e7-c7a5-49cd-aa1f-5a34f0adddd5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3e5dc8e7-c7a5-49cd-aa1f-5a34f0adddd5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 84,\n  \"fields\": [\n    {\n      \"column\": \"avg_f0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.93528100367362,\n        \"min\": 135.35,\n        \"max\": 350.85,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          294.0,\n          304.75,\n          309.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140.3576334301769,\n        \"min\": 568.1,\n        \"max\": 1265.75,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          1059.05,\n          778.0,\n          988.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 137.49529674321965,\n        \"min\": 1938.95,\n        \"max\": 2633.3,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2230.45,\n          2245.6,\n          2208.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146.69919028677222,\n        \"min\": 3177.75,\n        \"max\": 3970.9,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          3347.85,\n          3571.05,\n          3485.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.29389461186318,\n        \"min\": 4581.1,\n        \"max\": 5302.25,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          5033.95,\n          5081.95,\n          5029.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3361199909599972,\n        \"min\": 4.9,\n        \"max\": 16.55,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          4.9,\n          10.75,\n          11.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4169873261634001,\n        \"min\": 0.735873708,\n        \"max\": 3.024994612,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.991100056,\n          1.95856664,\n          1.028821193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20425923839610602,\n        \"min\": 0.816624405,\n        \"max\": 1.842686333,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1.020546757,\n          1.377359646,\n          0.928831882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.81632459238096,\n        \"min\": 1159.033333,\n        \"max\": 1506.983333,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1416.383333,\n          1434.65,\n          1403.416667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.149139715121006,\n        \"min\": 1.502538523,\n        \"max\": 14.22461757,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          5.830436913,\n          4.12059635,\n          2.619929051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0113270482798784,\n        \"min\": 1.636628881,\n        \"max\": 6.520670194,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2.932875765,\n          6.512729092,\n          2.67471935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.384573981241517,\n        \"min\": 1.708948397,\n        \"max\": 12.78754799,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          4.582699122,\n          4.430703242,\n          3.964456781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2824950760353502,\n        \"min\": 1.834133086,\n        \"max\": 9.666449675,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2.834775216,\n          2.066857991,\n          2.495128841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.684444398329073,\n        \"min\": 1.632534979,\n        \"max\": 5.19315907,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          3.038196117,\n          5.19315907,\n          2.257816636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0098806312022794,\n        \"min\": -2.734113835,\n        \"max\": 3.425743983,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          -1.328045265,\n          1.026296327,\n          0.157130814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5344824448074714,\n        \"min\": -0.622791378,\n        \"max\": 1.761441582,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.148278373,\n          1.519205733,\n          -0.466922287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7472394249204369,\n        \"min\": -0.439475583,\n        \"max\": 3.104094568,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1.352627409,\n          1.205159556,\n          0.980843827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6551324634987853,\n        \"min\": -1.606129365,\n        \"max\": 2.336159712,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.308434341,\n          -0.259522013,\n          -0.163107758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5029627591740098,\n        \"min\": -1.157513779,\n        \"max\": 1.126439929,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          -1.128668719,\n          0.069056976,\n          0.195156412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: The scikit-learn developers\n",
        "# SPDX-License-Identifier: BSD-3-Clause\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        (\"rfe\", RFE(estimator=LogisticRegression(), n_features_to_select=4, step=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipe.fit(X, y)\n",
        "\n",
        "print(\"First 4 best features: \", pipe.get_feature_names_out())\n",
        "\n",
        "ranking = pipe.named_steps[\"rfe\"].ranking_\n",
        "ranking = ranking.reshape(1, -1)\n",
        "\n",
        "# Plot pixel ranking\n",
        "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
        "\n",
        "# Add annotations for pixel numbers\n",
        "for i in range(ranking.shape[0]):\n",
        "    for j in range(ranking.shape[1]):\n",
        "        plt.text(j, i, str(ranking[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
        "\n",
        "plt.colorbar()\n",
        "plt.title(\"Ranking of features with RFE\\n(Logistic Regression)\")\n",
        "plt.show()\n",
        "\n",
        "print('\\ny: ' , len(y))\n",
        "print('\\nX: ', len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "72qjugSHPT36",
        "outputId": "01a4e6f8-ea6c-4c3c-afe6-10bdccfa6e70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 4 best features:  ['avg_f0' 'jitter' 'shimmer' 'avg_f0_s']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "y:  84\n",
            "\n",
            "X:  84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "my = np.array(np.arange(0.62, 1.1, 0.15))\n",
        "mx = np.array([4]*(len(my)))\n",
        "plt.plot(mx,my,c='red', linestyle='--')\n",
        "plt.ylabel('Cummulative explained variance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8zgnuvQ7J7C9",
        "outputId": "b9d83a1b-536a-49e5-db77-4c89d3c0d63d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca.n_components = 4\n",
        "X = pca.fit_transform(X)\n",
        "print(\"Explained Variance Ratio: \", sum(pca.explained_variance_ratio_))\n",
        "display(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "44e0b1ea-bbe1-467c-cbff-e615bf4eadf0",
        "id": "xMcnZy-KWTB_"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio:  0.9890077247677216\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
        "from scipy.stats import mode\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, silhouette_score\n",
        "\n",
        "# Initialize StratifiedShuffleSplit Cross-Validation\n",
        "strat_shuffle_split = StratifiedShuffleSplit(n_splits=50, train_size=0.7, test_size=0.3, random_state=0)\n",
        "\n",
        "# Get the train/test indices for one split\n",
        "train_index, test_index = next(strat_shuffle_split.split(X, y)) # Get indices for one split\n",
        "X_train, X_test = X[train_index], X[test_index] # Use indices to split X data\n",
        "y_train, y_test = y[train_index], y[test_index] # Use indices to split y data\n",
        "\n",
        "# Store ROC values for averaging\n",
        "tprs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "# Store confusion matrices\n",
        "conf_matrices = []\n",
        "\n",
        "# For now, it will run a single iteration using the current train/test splits\n",
        "#for train_index, test_index in [(train_index, test_index)]: # Using existing splits\n",
        "for i, (train_index, test_index) in enumerate(strat_shuffle_split.split(X, y)):\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    print(\"******************************\")\n",
        "    # Apply K-Means++ Clustering\n",
        "    kmeans = KMeans(n_clusters=2, init=\"k-means++\", random_state=0, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(X_train)\n",
        "\n",
        "    # Map Cluster Labels to Ground Truth Labels\n",
        "    # Ensure that mapping creates at least two unique labels\n",
        "    # Check the distribution of y_train within each cluster to determine the appropriate mapping\n",
        "    mapping = {}\n",
        "    for j in np.unique(cluster_labels):\n",
        "      # Get the most frequent ground truth label within the cluster\n",
        "      most_frequent_label = mode(y_train[cluster_labels == j], keepdims=True).mode[0]\n",
        "\n",
        "      # If the most frequent label is already in the mapping and it's the same as the current cluster\n",
        "      #  then assign a different label to ensure at least two unique labels\n",
        "      if most_frequent_label in mapping.values() and list(mapping.keys())[list(mapping.values()).index(most_frequent_label)] != j:\n",
        "        # Assign the opposite label (1 if most frequent is 0, and vice versa)\n",
        "        mapping[j] = 1 - most_frequent_label\n",
        "      else:\n",
        "        mapping[j] = most_frequent_label\n",
        "\n",
        "    mapped_preds = np.vectorize(mapping.get)(kmeans.predict(X_test))\n",
        "\n",
        "    print(f\"Fold {i+1}: \\n\")\n",
        "    print(\"\\nCluster Labels: \\n\", cluster_labels)\n",
        "    print(\"\\nKMeans++ Score: \\n\", kmeans.score(X_test))\n",
        "    print(\"\\nMapping predictions: \\n\", mapped_preds)\n",
        "    print(\"\\nGround Truth: \\n\", y_test)\n",
        "    accuracy_score = np.mean(mapped_preds == y_test)\n",
        "    print(\"\\nAccuracy Score: \", accuracy_score)\n",
        "    print(\"\\nClassification Report: \\n\", classification_report(y_test, mapped_preds))\n",
        "    current_silhouette_score = silhouette_score(X_test, mapped_preds) # Change variable name to avoid overwriting the function\n",
        "    print(\"\\nSilhouette Score: \", current_silhouette_score)\n",
        "\n",
        "    # Compute ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, mapped_preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"\\nROC_AUC: \", roc_auc, \"\\n\")\n",
        "\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area) = {roc_auc:0.2f}\")\n",
        "    plt.plot([0,1], [0,1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"StratifiedShuffleSplit Cross-Validation with ROC Scoring Fold #{i+1}\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show\n",
        "\n",
        "    \"\"\"\n",
        "    tprs.append(np.interp(mean_fpr, fpr, tpr)) #Fixed indentation\n",
        "\n",
        "    # Compute Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, mapped_preds)\n",
        "\n",
        "    # Ensure confusion matrix is always 2x2\n",
        "    if cm.shape != (2, 2):\n",
        "        cm_padded = np.zeros((2, 2), dtype=int)\n",
        "        cm_padded[:cm.shape[0], :cm.shape[1]] = cm\n",
        "        cm = cm_padded\n",
        "\n",
        "    conf_matrices.append(cm)\n",
        "    print(\"\\nConfusion Matrix: \\n\", cm)\n",
        "    print(\"\\n******************************\\n\")\n",
        "\n",
        "\n",
        "# Compute Mean ROC Curve\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "# Compute Average Confusion Matrix\n",
        "avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n",
        "\"\"\"\n",
        "# Plot Average Confusion Matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(avg_conf_matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Average Confusion Matrix Across Folds\")\n",
        "plt.show()\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ieBGSBzkPUie",
        "outputId": "eb81cca0-e7b2-490d-a974-6ae6c7a1f547"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************\n",
            "Fold 1: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 2: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 3: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 4: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 5: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 6: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 7: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 8: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 9: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 10: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 11: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 12: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 13: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 14: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 15: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 16: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 17: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 18: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 19: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 20: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 21: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 22: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 23: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 24: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 25: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 26: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 27: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 28: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 29: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 30: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 31: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 32: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 33: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 34: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 35: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 36: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 37: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 38: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 39: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 40: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 41: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 42: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 43: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 44: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 45: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 46: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 47: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 48: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 49: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 50: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1400495.9563915594\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        18\n",
            "           1       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.63      0.65      0.63        26\n",
            "weighted avg       0.69      0.65      0.67        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3320596616867625\n",
            "\n",
            "ROC_AUC:  0.6458333333333334 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  6]\n",
            " [ 3  5]]\n",
            "\n",
            "******************************\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Plot Average Confusion Matrix\\nplt.figure(figsize=(5, 4))\\nsns.heatmap(avg_conf_matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=[0,1], yticklabels=[0,1])\\nplt.xlabel(\"Predicted Label\")\\nplt.ylabel(\"True Label\")\\nplt.title(\"Average Confusion Matrix Across Folds\")\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "986a77ad-e287-41a6-ef4f-b7bb4d23e182",
        "id": "dmpHxMbB6bvC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  6]\n",
            " [ 3  5]]\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Displaying KMeans++ confusion matrix for\n",
        "#2 classes (Groups - ASD and CTRL) - (NO TD))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(cm)\n",
        "print(cm.shape[0])\n",
        "print(cm.shape[1])\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(x=j, y=i,s=cm[i, j], va='center',\n",
        "                ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Average Confusion Matrix Across Folds', fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "# Compute Average Confusion Matrix\n",
        "avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilisation de SVC Cross-Validation (CV) avec ROC scoring.\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, classification_report, fowlkes_mallows_score, normalized_mutual_info_score, silhouette_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "rs = ShuffleSplit(n_splits=100, train_size=0.7, test_size=0.3, random_state=13)\n",
        "\n",
        "#Creation du SVC pour la classification\n",
        "model_SVC = SVC(kernel=\"linear\", probability=True, random_state=13)\n",
        "\n",
        "# Fit KMeans on the training data\n",
        "model_KMeans = KMeans(n_clusters=2, max_iter=50, init=\"k-means++\", random_state=13)\n",
        "clustered_labels = model_KMeans.fit_predict(X, y)\n",
        "\n",
        "#Evaluate clustering\n",
        "silhouette_avg = silhouette_score(X, clustered_labels)\n",
        "print(\"For model_KMeans: \\n\", model_KMeans.get_params(), \"\\nThe average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "# Split train/test (70%/30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, clustered_labels, test_size=0.3, random_state=0)\n",
        "\n",
        "# Apply Supervised KMeans classification on clustered training data and perform cross-validation.\n",
        "scores = cross_val_score(model_SVC, X_train, y_train, cv=rs, verbose=5, scoring='roc_auc')\n",
        "scores = scores[~np.isnan(scores)]\n",
        "print(\"\\nMeans Model classification with cross-validation score: \", np.mean(scores))\n",
        "\n",
        "#Display results\n",
        "y_pred = model_SVC.fit(X_train, y_train).predict(X_train)\n",
        "print(\"\\nAccuracy Score: \", accuracy_score(y_train, y_pred))\n",
        "print(\"\\nClassification Report: \\n\", classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORpVVPPO8IB3",
        "outputId": "57ba4aa7-73a3-481f-b573-cdb5874c1510"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For model_KMeans: \n",
            " {'algorithm': 'lloyd', 'copy_x': True, 'init': 'k-means++', 'max_iter': 50, 'n_clusters': 2, 'n_init': 'auto', 'random_state': 13, 'tol': 0.0001, 'verbose': 0} \n",
            "The average silhouette_score is : 0.31086097104343385\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.938) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.987) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.978) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.948) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.985) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.982) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.954) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.987) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.964) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.929) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.985) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.978) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "\n",
            "Means Model classification with cross-validation score:  0.9961027468603226\n",
            "\n",
            "Accuracy Score:  1.0\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        43\n",
            "\n",
            "    accuracy                           1.00        58\n",
            "   macro avg       1.00      1.00      1.00        58\n",
            "weighted avg       1.00      1.00      1.00        58\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "65a2c119-b0ee-4cdf-c518-101a4bb32711",
        "id": "oxASIkZ6UcMt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15  0]\n",
            " [ 0 43]]\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Displaying KMeans++ confusion matrix for\n",
        "#2 classes (Groups - ASD and CTRL) - (NO TD))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(cm)\n",
        "print(cm.shape[0])\n",
        "print(cm.shape[1])\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(x=j, y=i,s=cm[i, j], va='center',\n",
        "                ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Shuffle Plit SVC Confusion Matrix', fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "# Compute Average Confusion Matrix\n",
        "avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lDTkX_QMpOfBTMqZ4UlRvH7sAOTiNU9Y",
      "authorship_tag": "ABX9TyPbDWWHjNbJGeuOQkl1jXwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}