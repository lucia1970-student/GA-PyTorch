{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia1970-student/GA-PyTorch/blob/main/Supervised_KMeans%2B%2B_ROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxu9rJzQwoBL",
        "outputId": "f827b022-b68d-45ec-a990-febc392cd96a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCCZxwfko-1H",
        "outputId": "d2f467d1-e781-4cff-a0ac-825d57543a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/cours_python/FSCI2610/projet\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/cours_python/FSCI2610/projet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k2JZFC_1o8Dy",
        "outputId": "59f388de-df78-463e-96ec-ce881ce5aa36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Group  avg_f0   avg_F1   avg_F2   avg_F3   avg_F4  mean_hnr    jitter  \\\n",
              "0     ASD  304.75   778.00  2245.60  3571.05  5081.95     10.75  1.958567   \n",
              "1     ASD  294.45   662.70  1939.90  3251.25  4775.30     12.25  1.663247   \n",
              "2     ASD  255.85   884.55  2183.50  3513.75  5111.40     12.90  1.422039   \n",
              "3     ASD  292.75   652.05  2022.60  3177.75  4634.10      8.65  1.729150   \n",
              "4     ASD  305.75   739.75  2294.25  3706.60  4807.55      8.30  2.033454   \n",
              "..    ...     ...      ...      ...      ...      ...       ...       ...   \n",
              "103    TD  255.05   858.95  2223.80  3384.55  4787.25      9.75  1.111741   \n",
              "104    TD  265.00  1022.95  2350.50  3596.25  4973.85      9.80  2.340409   \n",
              "105    TD  266.45   762.45  2278.70  3557.60  4742.95     10.95  1.489093   \n",
              "106    TD  274.95   873.00  2299.70  3672.65  4917.65      9.35  1.391963   \n",
              "107    TD  149.75  1102.55  2514.30  3747.50  5209.35      7.25  2.516211   \n",
              "\n",
              "      shimmer  dispersion_formantique  avg_f0_k  mean_hnr_k  jitter_k  \\\n",
              "0    1.377360             1434.650000  4.120596    6.512729  4.430703   \n",
              "1    1.389308             1370.866667  2.278845    3.440682  3.091686   \n",
              "2    1.185426             1408.950000  1.737850    5.391922  2.999970   \n",
              "3    1.645441             1327.350000  8.688811    2.620909  2.320086   \n",
              "4    1.544171             1355.933333  3.761873    3.485672  3.841500   \n",
              "..        ...                     ...       ...         ...       ...   \n",
              "103  1.302515             1309.433333  5.190369    3.365465  1.875519   \n",
              "104  1.299065             1316.966667  3.619754    6.548035  8.302562   \n",
              "105  1.517415             1326.833333  2.151113    2.531716  3.208905   \n",
              "106  1.264749             1348.216667  3.473041    2.755562  2.825725   \n",
              "107  1.570721             1368.933333  3.456351    5.940674  2.695571   \n",
              "\n",
              "     shimmer_k  dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s  \\\n",
              "0     2.066858                  5.193159  1.026296    1.519206  1.205160   \n",
              "1     3.108758                  2.927942  0.133170    0.667077  0.560049   \n",
              "2     3.019235                  2.481138  0.169958    1.548892  0.722608   \n",
              "3     2.652073                  2.249446 -2.098723   -0.134290  0.045519   \n",
              "4     7.036189                  3.318189  0.993320    0.670789  1.151768   \n",
              "..         ...                       ...       ...         ...       ...   \n",
              "103   3.242620                  1.881098  1.338850    0.806779  0.273689   \n",
              "104   2.789693                  4.012588  1.028263    1.752227  2.363517   \n",
              "105   2.385634                  3.771958  0.114164    0.130736  0.951328   \n",
              "106   2.361107                  2.442094 -0.777756    0.412494  0.655506   \n",
              "107   2.150739                  2.009205  1.171288    1.303329  0.610251   \n",
              "\n",
              "     shimmer_s  dispersion_formantique_s  \n",
              "0    -0.259522                  0.069057  \n",
              "1    -0.244830                 -0.390032  \n",
              "2    -0.348192                  0.175821  \n",
              "3     0.452664                  0.225971  \n",
              "4    -1.606129                 -0.338201  \n",
              "..         ...                       ...  \n",
              "103  -0.246472                  0.152368  \n",
              "104   0.612808                  0.451664  \n",
              "105  -0.507807                  1.004282  \n",
              "106   0.554750                 -0.074498  \n",
              "107   0.011729                  0.064346  \n",
              "\n",
              "[108 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0c1f7ea-68df-4c27-bc50-c15963b437d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Group</th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ASD</td>\n",
              "      <td>304.75</td>\n",
              "      <td>778.00</td>\n",
              "      <td>2245.60</td>\n",
              "      <td>3571.05</td>\n",
              "      <td>5081.95</td>\n",
              "      <td>10.75</td>\n",
              "      <td>1.958567</td>\n",
              "      <td>1.377360</td>\n",
              "      <td>1434.650000</td>\n",
              "      <td>4.120596</td>\n",
              "      <td>6.512729</td>\n",
              "      <td>4.430703</td>\n",
              "      <td>2.066858</td>\n",
              "      <td>5.193159</td>\n",
              "      <td>1.026296</td>\n",
              "      <td>1.519206</td>\n",
              "      <td>1.205160</td>\n",
              "      <td>-0.259522</td>\n",
              "      <td>0.069057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ASD</td>\n",
              "      <td>294.45</td>\n",
              "      <td>662.70</td>\n",
              "      <td>1939.90</td>\n",
              "      <td>3251.25</td>\n",
              "      <td>4775.30</td>\n",
              "      <td>12.25</td>\n",
              "      <td>1.663247</td>\n",
              "      <td>1.389308</td>\n",
              "      <td>1370.866667</td>\n",
              "      <td>2.278845</td>\n",
              "      <td>3.440682</td>\n",
              "      <td>3.091686</td>\n",
              "      <td>3.108758</td>\n",
              "      <td>2.927942</td>\n",
              "      <td>0.133170</td>\n",
              "      <td>0.667077</td>\n",
              "      <td>0.560049</td>\n",
              "      <td>-0.244830</td>\n",
              "      <td>-0.390032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ASD</td>\n",
              "      <td>255.85</td>\n",
              "      <td>884.55</td>\n",
              "      <td>2183.50</td>\n",
              "      <td>3513.75</td>\n",
              "      <td>5111.40</td>\n",
              "      <td>12.90</td>\n",
              "      <td>1.422039</td>\n",
              "      <td>1.185426</td>\n",
              "      <td>1408.950000</td>\n",
              "      <td>1.737850</td>\n",
              "      <td>5.391922</td>\n",
              "      <td>2.999970</td>\n",
              "      <td>3.019235</td>\n",
              "      <td>2.481138</td>\n",
              "      <td>0.169958</td>\n",
              "      <td>1.548892</td>\n",
              "      <td>0.722608</td>\n",
              "      <td>-0.348192</td>\n",
              "      <td>0.175821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ASD</td>\n",
              "      <td>292.75</td>\n",
              "      <td>652.05</td>\n",
              "      <td>2022.60</td>\n",
              "      <td>3177.75</td>\n",
              "      <td>4634.10</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.729150</td>\n",
              "      <td>1.645441</td>\n",
              "      <td>1327.350000</td>\n",
              "      <td>8.688811</td>\n",
              "      <td>2.620909</td>\n",
              "      <td>2.320086</td>\n",
              "      <td>2.652073</td>\n",
              "      <td>2.249446</td>\n",
              "      <td>-2.098723</td>\n",
              "      <td>-0.134290</td>\n",
              "      <td>0.045519</td>\n",
              "      <td>0.452664</td>\n",
              "      <td>0.225971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ASD</td>\n",
              "      <td>305.75</td>\n",
              "      <td>739.75</td>\n",
              "      <td>2294.25</td>\n",
              "      <td>3706.60</td>\n",
              "      <td>4807.55</td>\n",
              "      <td>8.30</td>\n",
              "      <td>2.033454</td>\n",
              "      <td>1.544171</td>\n",
              "      <td>1355.933333</td>\n",
              "      <td>3.761873</td>\n",
              "      <td>3.485672</td>\n",
              "      <td>3.841500</td>\n",
              "      <td>7.036189</td>\n",
              "      <td>3.318189</td>\n",
              "      <td>0.993320</td>\n",
              "      <td>0.670789</td>\n",
              "      <td>1.151768</td>\n",
              "      <td>-1.606129</td>\n",
              "      <td>-0.338201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>TD</td>\n",
              "      <td>255.05</td>\n",
              "      <td>858.95</td>\n",
              "      <td>2223.80</td>\n",
              "      <td>3384.55</td>\n",
              "      <td>4787.25</td>\n",
              "      <td>9.75</td>\n",
              "      <td>1.111741</td>\n",
              "      <td>1.302515</td>\n",
              "      <td>1309.433333</td>\n",
              "      <td>5.190369</td>\n",
              "      <td>3.365465</td>\n",
              "      <td>1.875519</td>\n",
              "      <td>3.242620</td>\n",
              "      <td>1.881098</td>\n",
              "      <td>1.338850</td>\n",
              "      <td>0.806779</td>\n",
              "      <td>0.273689</td>\n",
              "      <td>-0.246472</td>\n",
              "      <td>0.152368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>TD</td>\n",
              "      <td>265.00</td>\n",
              "      <td>1022.95</td>\n",
              "      <td>2350.50</td>\n",
              "      <td>3596.25</td>\n",
              "      <td>4973.85</td>\n",
              "      <td>9.80</td>\n",
              "      <td>2.340409</td>\n",
              "      <td>1.299065</td>\n",
              "      <td>1316.966667</td>\n",
              "      <td>3.619754</td>\n",
              "      <td>6.548035</td>\n",
              "      <td>8.302562</td>\n",
              "      <td>2.789693</td>\n",
              "      <td>4.012588</td>\n",
              "      <td>1.028263</td>\n",
              "      <td>1.752227</td>\n",
              "      <td>2.363517</td>\n",
              "      <td>0.612808</td>\n",
              "      <td>0.451664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>TD</td>\n",
              "      <td>266.45</td>\n",
              "      <td>762.45</td>\n",
              "      <td>2278.70</td>\n",
              "      <td>3557.60</td>\n",
              "      <td>4742.95</td>\n",
              "      <td>10.95</td>\n",
              "      <td>1.489093</td>\n",
              "      <td>1.517415</td>\n",
              "      <td>1326.833333</td>\n",
              "      <td>2.151113</td>\n",
              "      <td>2.531716</td>\n",
              "      <td>3.208905</td>\n",
              "      <td>2.385634</td>\n",
              "      <td>3.771958</td>\n",
              "      <td>0.114164</td>\n",
              "      <td>0.130736</td>\n",
              "      <td>0.951328</td>\n",
              "      <td>-0.507807</td>\n",
              "      <td>1.004282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>TD</td>\n",
              "      <td>274.95</td>\n",
              "      <td>873.00</td>\n",
              "      <td>2299.70</td>\n",
              "      <td>3672.65</td>\n",
              "      <td>4917.65</td>\n",
              "      <td>9.35</td>\n",
              "      <td>1.391963</td>\n",
              "      <td>1.264749</td>\n",
              "      <td>1348.216667</td>\n",
              "      <td>3.473041</td>\n",
              "      <td>2.755562</td>\n",
              "      <td>2.825725</td>\n",
              "      <td>2.361107</td>\n",
              "      <td>2.442094</td>\n",
              "      <td>-0.777756</td>\n",
              "      <td>0.412494</td>\n",
              "      <td>0.655506</td>\n",
              "      <td>0.554750</td>\n",
              "      <td>-0.074498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>TD</td>\n",
              "      <td>149.75</td>\n",
              "      <td>1102.55</td>\n",
              "      <td>2514.30</td>\n",
              "      <td>3747.50</td>\n",
              "      <td>5209.35</td>\n",
              "      <td>7.25</td>\n",
              "      <td>2.516211</td>\n",
              "      <td>1.570721</td>\n",
              "      <td>1368.933333</td>\n",
              "      <td>3.456351</td>\n",
              "      <td>5.940674</td>\n",
              "      <td>2.695571</td>\n",
              "      <td>2.150739</td>\n",
              "      <td>2.009205</td>\n",
              "      <td>1.171288</td>\n",
              "      <td>1.303329</td>\n",
              "      <td>0.610251</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.064346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows Ã— 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0c1f7ea-68df-4c27-bc50-c15963b437d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0c1f7ea-68df-4c27-bc50-c15963b437d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0c1f7ea-68df-4c27-bc50-c15963b437d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee9325f0-31b3-4943-8a9e-71f5bb763475\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee9325f0-31b3-4943-8a9e-71f5bb763475')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee9325f0-31b3-4943-8a9e-71f5bb763475 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4c713a0f-1468-450d-a0fc-67257cd188c2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4c713a0f-1468-450d-a0fc-67257cd188c2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 108,\n  \"fields\": [\n    {\n      \"column\": \"Group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SLI\",\n          \"TD\",\n          \"ASD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.16771777220911,\n        \"min\": 135.35,\n        \"max\": 350.85,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          215.35,\n          242.35,\n          305.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.99713570968208,\n        \"min\": 568.1,\n        \"max\": 1265.75,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          719.1,\n          568.1,\n          739.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 136.47788514342105,\n        \"min\": 1938.95,\n        \"max\": 2633.3,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2259.5,\n          2164.15,\n          2294.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139.67710633553338,\n        \"min\": 3177.75,\n        \"max\": 3970.9,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3417.8,\n          3594.7,\n          3706.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.18893719350055,\n        \"min\": 4581.1,\n        \"max\": 5302.25,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          4635.85,\n          4882.15,\n          4807.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4089801040933527,\n        \"min\": 4.9,\n        \"max\": 16.55,\n        \"num_unique_values\": 86,\n        \"samples\": [\n          7.7,\n          10.75,\n          8.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4010864360120488,\n        \"min\": 0.735873708,\n        \"max\": 3.024994612,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.195084014,\n          1.274712822,\n          2.033453727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19359601392765116,\n        \"min\": 0.816624405,\n        \"max\": 1.842686333,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.223120187,\n          1.428855234,\n          1.544170528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.44555455156344,\n        \"min\": 1159.033333,\n        \"max\": 1506.983333,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1305.583333,\n          1438.016667,\n          1355.933333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.268528561677701,\n        \"min\": 1.502538523,\n        \"max\": 14.22461757,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3.027195528,\n          3.649101316,\n          3.761873329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0840278158327785,\n        \"min\": 1.636628881,\n        \"max\": 6.548035431,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.509274249,\n          1.789300412,\n          3.485671715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.705186649411072,\n        \"min\": 1.708948397,\n        \"max\": 13.88318885,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          4.154415567,\n          2.814530876,\n          3.841500406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.323388126187469,\n        \"min\": 1.834133086,\n        \"max\": 9.666449675,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.09295084,\n          3.457993601,\n          7.036189341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7051505343774105,\n        \"min\": 1.632534979,\n        \"max\": 5.19315907,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          2.704034183,\n          4.223795797,\n          3.31818879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.022456312380928,\n        \"min\": -2.734113835,\n        \"max\": 3.425743983,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          -0.265908939,\n          0.898138225,\n          0.993319641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5506275552762182,\n        \"min\": -0.669774925,\n        \"max\": 1.761441582,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          0.115366857,\n          -0.163299316,\n          0.670789359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8102158693374696,\n        \"min\": -0.439475583,\n        \"max\": 3.303385805,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          1.193736424,\n          0.562025818,\n          1.151768479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6605966932303408,\n        \"min\": -1.606129365,\n        \"max\": 2.336159712,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          -0.121888845,\n          -0.154744973,\n          -1.606129365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4935783028237649,\n        \"min\": -1.157513779,\n        \"max\": 1.126439929,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          0.387588852,\n          -0.122836266,\n          -0.338201178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['Group', 'avg_f0', 'avg_F1', 'avg_F2', 'avg_F3', 'avg_F4', 'mean_hnr',\n",
              "       'jitter', 'shimmer', 'dispersion_formantique', 'avg_f0_k', 'mean_hnr_k',\n",
              "       'jitter_k', 'shimmer_k', 'dispersion_formantique_k', 'avg_f0_s',\n",
              "       'mean_hnr_s', 'jitter_s', 'shimmer_s', 'dispersion_formantique_s'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTRL count without TD (24):  70\n",
            "ASD count:  38\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Group  avg_f0  avg_F1   avg_F2   avg_F3   avg_F4   mean_hnr  jitter    shimmer   dispersion_formantique  avg_f0_k  mean_hnr_k  jitter_k  shimmer_k  dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s   shimmer_s  dispersion_formantique_s\n",
              "ASD    135.35  988.15   2393.45  3640.05  4875.60  4.90      1.490435  1.602262  1295.816667             7.724096  3.591570    5.565571  7.160721   1.632535                  2.314049   0.899021    1.875244   2.080483   0.021249                   1\n",
              "SLI    267.15  950.75   2354.50  3420.55  4681.85  9.80      1.222840  1.100797  1243.700000             3.163465  2.026336    2.003743  2.851964   2.089819                  0.824082   0.472550    0.358002   0.339679  -0.061841                   1\n",
              "       300.80  769.60   2079.05  3331.15  4790.55  14.15     0.790875  1.102135  1340.316667             3.220332  2.145983    2.468427  2.772546   3.880961                  1.094163   0.190177    0.845510   0.510875   0.261225                   1\n",
              "       300.30  1001.35  2518.35  3970.90  5302.25  13.30     1.498298  1.501590  1433.633333             3.677679  2.536378    4.656360  5.951269   3.461849                  0.711598   0.362425    1.380237   0.763329   0.567253                   1\n",
              "       291.35  1029.95  2440.60  3591.35  4955.00  10.15     1.155211  1.010466  1308.350000             6.415412  6.520670    2.538592  2.137952   2.184312                  1.744851   1.761442    0.915314   0.059145   0.006798                   1\n",
              "                                                                                                                                                                                                                                                     ..\n",
              "ASD    335.30  668.75   2005.45  3214.50  4607.80  9.60      1.705673  1.562046  1313.016667             3.668807  3.216171    2.332092  3.348500   2.970892                  0.467641   0.735932    0.271600  -0.835370  -0.251010                   1\n",
              "       334.10  684.90   2094.30  3579.70  4856.10  11.30     2.190127  1.458687  1390.400000             3.270168  2.770940    2.156335  2.384491   3.616185                  0.073779   0.540132   -0.271603  -0.347822   0.721927                   1\n",
              "       331.95  779.30   2271.30  3687.00  4806.70  9.30      1.989887  1.514565  1342.466667             3.788538  2.111079    3.193975  3.715863   2.814807                  0.336245  -0.508081    0.757273   1.094934   0.379331                   1\n",
              "       325.80  773.75   2243.80  3530.95  4862.85  8.50      2.070477  1.697217  1363.033333             8.262409  2.766723    2.527389  2.369298   2.733893                  2.055750  -0.081247    0.729531  -0.299465   0.665008                   1\n",
              "TD     319.55  1073.60  2495.70  3786.50  4988.30  7.70      1.153545  1.174254  1304.900000             2.853541  2.986775    4.395455  2.258666   2.654484                  0.807288  -0.228113    1.250874   0.182217   0.282963                   1\n",
              "Name: count, Length: 108, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Group</th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ASD</th>\n",
              "      <th>135.35</th>\n",
              "      <th>988.15</th>\n",
              "      <th>2393.45</th>\n",
              "      <th>3640.05</th>\n",
              "      <th>4875.60</th>\n",
              "      <th>4.90</th>\n",
              "      <th>1.490435</th>\n",
              "      <th>1.602262</th>\n",
              "      <th>1295.816667</th>\n",
              "      <th>7.724096</th>\n",
              "      <th>3.591570</th>\n",
              "      <th>5.565571</th>\n",
              "      <th>7.160721</th>\n",
              "      <th>1.632535</th>\n",
              "      <th>2.314049</th>\n",
              "      <th>0.899021</th>\n",
              "      <th>1.875244</th>\n",
              "      <th>2.080483</th>\n",
              "      <th>0.021249</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">SLI</th>\n",
              "      <th>267.15</th>\n",
              "      <th>950.75</th>\n",
              "      <th>2354.50</th>\n",
              "      <th>3420.55</th>\n",
              "      <th>4681.85</th>\n",
              "      <th>9.80</th>\n",
              "      <th>1.222840</th>\n",
              "      <th>1.100797</th>\n",
              "      <th>1243.700000</th>\n",
              "      <th>3.163465</th>\n",
              "      <th>2.026336</th>\n",
              "      <th>2.003743</th>\n",
              "      <th>2.851964</th>\n",
              "      <th>2.089819</th>\n",
              "      <th>0.824082</th>\n",
              "      <th>0.472550</th>\n",
              "      <th>0.358002</th>\n",
              "      <th>0.339679</th>\n",
              "      <th>-0.061841</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300.80</th>\n",
              "      <th>769.60</th>\n",
              "      <th>2079.05</th>\n",
              "      <th>3331.15</th>\n",
              "      <th>4790.55</th>\n",
              "      <th>14.15</th>\n",
              "      <th>0.790875</th>\n",
              "      <th>1.102135</th>\n",
              "      <th>1340.316667</th>\n",
              "      <th>3.220332</th>\n",
              "      <th>2.145983</th>\n",
              "      <th>2.468427</th>\n",
              "      <th>2.772546</th>\n",
              "      <th>3.880961</th>\n",
              "      <th>1.094163</th>\n",
              "      <th>0.190177</th>\n",
              "      <th>0.845510</th>\n",
              "      <th>0.510875</th>\n",
              "      <th>0.261225</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300.30</th>\n",
              "      <th>1001.35</th>\n",
              "      <th>2518.35</th>\n",
              "      <th>3970.90</th>\n",
              "      <th>5302.25</th>\n",
              "      <th>13.30</th>\n",
              "      <th>1.498298</th>\n",
              "      <th>1.501590</th>\n",
              "      <th>1433.633333</th>\n",
              "      <th>3.677679</th>\n",
              "      <th>2.536378</th>\n",
              "      <th>4.656360</th>\n",
              "      <th>5.951269</th>\n",
              "      <th>3.461849</th>\n",
              "      <th>0.711598</th>\n",
              "      <th>0.362425</th>\n",
              "      <th>1.380237</th>\n",
              "      <th>0.763329</th>\n",
              "      <th>0.567253</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291.35</th>\n",
              "      <th>1029.95</th>\n",
              "      <th>2440.60</th>\n",
              "      <th>3591.35</th>\n",
              "      <th>4955.00</th>\n",
              "      <th>10.15</th>\n",
              "      <th>1.155211</th>\n",
              "      <th>1.010466</th>\n",
              "      <th>1308.350000</th>\n",
              "      <th>6.415412</th>\n",
              "      <th>6.520670</th>\n",
              "      <th>2.538592</th>\n",
              "      <th>2.137952</th>\n",
              "      <th>2.184312</th>\n",
              "      <th>1.744851</th>\n",
              "      <th>1.761442</th>\n",
              "      <th>0.915314</th>\n",
              "      <th>0.059145</th>\n",
              "      <th>0.006798</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ASD</th>\n",
              "      <th>335.30</th>\n",
              "      <th>668.75</th>\n",
              "      <th>2005.45</th>\n",
              "      <th>3214.50</th>\n",
              "      <th>4607.80</th>\n",
              "      <th>9.60</th>\n",
              "      <th>1.705673</th>\n",
              "      <th>1.562046</th>\n",
              "      <th>1313.016667</th>\n",
              "      <th>3.668807</th>\n",
              "      <th>3.216171</th>\n",
              "      <th>2.332092</th>\n",
              "      <th>3.348500</th>\n",
              "      <th>2.970892</th>\n",
              "      <th>0.467641</th>\n",
              "      <th>0.735932</th>\n",
              "      <th>0.271600</th>\n",
              "      <th>-0.835370</th>\n",
              "      <th>-0.251010</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334.10</th>\n",
              "      <th>684.90</th>\n",
              "      <th>2094.30</th>\n",
              "      <th>3579.70</th>\n",
              "      <th>4856.10</th>\n",
              "      <th>11.30</th>\n",
              "      <th>2.190127</th>\n",
              "      <th>1.458687</th>\n",
              "      <th>1390.400000</th>\n",
              "      <th>3.270168</th>\n",
              "      <th>2.770940</th>\n",
              "      <th>2.156335</th>\n",
              "      <th>2.384491</th>\n",
              "      <th>3.616185</th>\n",
              "      <th>0.073779</th>\n",
              "      <th>0.540132</th>\n",
              "      <th>-0.271603</th>\n",
              "      <th>-0.347822</th>\n",
              "      <th>0.721927</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331.95</th>\n",
              "      <th>779.30</th>\n",
              "      <th>2271.30</th>\n",
              "      <th>3687.00</th>\n",
              "      <th>4806.70</th>\n",
              "      <th>9.30</th>\n",
              "      <th>1.989887</th>\n",
              "      <th>1.514565</th>\n",
              "      <th>1342.466667</th>\n",
              "      <th>3.788538</th>\n",
              "      <th>2.111079</th>\n",
              "      <th>3.193975</th>\n",
              "      <th>3.715863</th>\n",
              "      <th>2.814807</th>\n",
              "      <th>0.336245</th>\n",
              "      <th>-0.508081</th>\n",
              "      <th>0.757273</th>\n",
              "      <th>1.094934</th>\n",
              "      <th>0.379331</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325.80</th>\n",
              "      <th>773.75</th>\n",
              "      <th>2243.80</th>\n",
              "      <th>3530.95</th>\n",
              "      <th>4862.85</th>\n",
              "      <th>8.50</th>\n",
              "      <th>2.070477</th>\n",
              "      <th>1.697217</th>\n",
              "      <th>1363.033333</th>\n",
              "      <th>8.262409</th>\n",
              "      <th>2.766723</th>\n",
              "      <th>2.527389</th>\n",
              "      <th>2.369298</th>\n",
              "      <th>2.733893</th>\n",
              "      <th>2.055750</th>\n",
              "      <th>-0.081247</th>\n",
              "      <th>0.729531</th>\n",
              "      <th>-0.299465</th>\n",
              "      <th>0.665008</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TD</th>\n",
              "      <th>319.55</th>\n",
              "      <th>1073.60</th>\n",
              "      <th>2495.70</th>\n",
              "      <th>3786.50</th>\n",
              "      <th>4988.30</th>\n",
              "      <th>7.70</th>\n",
              "      <th>1.153545</th>\n",
              "      <th>1.174254</th>\n",
              "      <th>1304.900000</th>\n",
              "      <th>2.853541</th>\n",
              "      <th>2.986775</th>\n",
              "      <th>4.395455</th>\n",
              "      <th>2.258666</th>\n",
              "      <th>2.654484</th>\n",
              "      <th>0.807288</th>\n",
              "      <th>-0.228113</th>\n",
              "      <th>1.250874</th>\n",
              "      <th>0.182217</th>\n",
              "      <th>0.282963</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Autism prognosis using voice biomarkers.\n",
        "\n",
        "#Dataset from study below.  Available on request.\n",
        "# https://www.nature.com/articles/s41398-023-02554-8#Fig2\n",
        "\n",
        "#I am proposing ALL characteristics of voice biomarkers (19) and 2 target\n",
        "#classes (CTRL (no TD) and ASD) in order to classify data.\n",
        "#The purpose of this iteration is to validate the study results.\n",
        "#The validation steps are detailed below:\n",
        "\n",
        "#1. Selecting ALL characteristicss and 2 classes ('ASD' and 'TD') as per study's\n",
        "#identified characteristics and classes.  The 19 characteristics have been ranked\n",
        "# with Recursive Feature Elimination (RFE).  No characteristics were eliminated at\n",
        "# this stage.\n",
        "\n",
        "#2. Applied feature rankings and applied  dimension reduction with RFE and PCA.\n",
        "# PCA components = 4 @ 99% coverage.  84 rows out 108, no rows were eliminated.\n",
        "\n",
        "#3. Split dataset into train/test (70%/30%) with StratifiedShuffleSplit and ran\n",
        "#multiple randomized folds of KMeans++ with k=2 while mapping clustering_labels\n",
        "#to actual values (Ground Truth) for each and finally computing ROC_AUC score\n",
        "# on the mapped results.  Many metrics for each foldis being shown.\n",
        "\n",
        "#4 Ploted the average ROC_AUC curve and plotted the confusion matrix.\n",
        "\n",
        "#5. As comparison, I have applied a ShuffleSplit cross-validation of SVC.\n",
        "#and displayed performance results.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#Load data.\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"voice_data.csv\")\n",
        "data=df.copy()\n",
        "display.max_columns = None\n",
        "display.nax_rows = None\n",
        "display(data)\n",
        "display(data.columns)\n",
        "\n",
        "a = np.count_nonzero(data.Group == 'TD')\n",
        "b = td_count = np.count_nonzero(data.Group == 'IC')\n",
        "c = td_count = np.count_nonzero(data.Group == 'SLI')\n",
        "d = np.count_nonzero(data.Group == 'ASD')\n",
        "z = a + b + c\n",
        "print('CTRL count without TD (24): ', z)\n",
        "print('ASD count: ', d)\n",
        "display(data.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Create a copy of the DataFrame before filtering and modifying it\n",
        "df_filtered = df[df['Group'] != 'TD'].copy()\n",
        "\n",
        "# Apply filtered DataFrame\n",
        "df_filtered['Group_Encoded'] = le.fit_transform(df_filtered['Group'])\n",
        "\n",
        "y = df_filtered['Group_Encoded'].values\n",
        "df_filtered.drop('Group_Encoded', axis=1, inplace=True)\n",
        "X = df_filtered.iloc[:, 1:]\n",
        "\n",
        "display(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "hwm_sxeNgBoj",
        "outputId": "8ce865a5-4cb6-4899-f998-143851217908"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    avg_f0   avg_F1   avg_F2   avg_F3   avg_F4  mean_hnr    jitter   shimmer  \\\n",
              "0   304.75   778.00  2245.60  3571.05  5081.95     10.75  1.958567  1.377360   \n",
              "1   294.45   662.70  1939.90  3251.25  4775.30     12.25  1.663247  1.389308   \n",
              "2   255.85   884.55  2183.50  3513.75  5111.40     12.90  1.422039  1.185426   \n",
              "3   292.75   652.05  2022.60  3177.75  4634.10      8.65  1.729150  1.645441   \n",
              "4   305.75   739.75  2294.25  3706.60  4807.55      8.30  2.033454  1.544171   \n",
              "..     ...      ...      ...      ...      ...       ...       ...       ...   \n",
              "79  272.40  1048.20  2396.10  3607.90  4777.30      8.65  1.148303  1.353881   \n",
              "80  301.10   782.05  2184.90  3415.10  4666.85     11.00  1.254625  0.952392   \n",
              "81  286.40   771.40  2272.80  3570.15  5088.50     10.35  1.583144  1.138822   \n",
              "82  261.35   682.65  2352.25  3547.65  5095.75     12.10  1.463657  1.052067   \n",
              "83  238.55  1020.15  2396.90  3565.35  4919.50      8.90  1.346442  1.266389   \n",
              "\n",
              "    dispersion_formantique   avg_f0_k  mean_hnr_k  jitter_k  shimmer_k  \\\n",
              "0              1434.650000   4.120596    6.512729  4.430703   2.066858   \n",
              "1              1370.866667   2.278845    3.440682  3.091686   3.108758   \n",
              "2              1408.950000   1.737850    5.391922  2.999970   3.019235   \n",
              "3              1327.350000   8.688811    2.620909  2.320086   2.652073   \n",
              "4              1355.933333   3.761873    3.485672  3.841500   7.036189   \n",
              "..                     ...        ...         ...       ...        ...   \n",
              "79             1243.033333   2.016973    2.138940  2.361210   3.209799   \n",
              "80             1294.933333  11.621063    2.995300  2.293056   2.490964   \n",
              "81             1439.033333   1.879826    4.383631  8.614788   2.707580   \n",
              "82             1471.033333   2.322844    1.838558  2.875774   1.973561   \n",
              "83             1299.783333   4.507005    2.386358  7.583330   2.475709   \n",
              "\n",
              "    dispersion_formantique_k  avg_f0_s  mean_hnr_s  jitter_s  shimmer_s  \\\n",
              "0                   5.193159  1.026296    1.519206  1.205160  -0.259522   \n",
              "1                   2.927942  0.133170    0.667077  0.560049  -0.244830   \n",
              "2                   2.481138  0.169958    1.548892  0.722608  -0.348192   \n",
              "3                   2.249446 -2.098723   -0.134290  0.045519   0.452664   \n",
              "4                   3.318189  0.993320    0.670789  1.151768  -1.606129   \n",
              "..                       ...       ...         ...       ...        ...   \n",
              "79                  2.195920 -0.675089   -0.074399  0.689445  -0.774658   \n",
              "80                  2.263339 -2.734114   -0.011581  0.444379   0.013398   \n",
              "81                  1.990779 -0.242029    1.170294  2.336884   0.309732   \n",
              "82                  2.330892  0.462941    0.378098  0.655235   0.279183   \n",
              "83                  1.914359 -1.598119    0.170505  2.139388   0.003517   \n",
              "\n",
              "    dispersion_formantique_s  \n",
              "0                   0.069057  \n",
              "1                  -0.390032  \n",
              "2                   0.175821  \n",
              "3                   0.225971  \n",
              "4                  -0.338201  \n",
              "..                       ...  \n",
              "79                 -0.183286  \n",
              "80                 -0.097667  \n",
              "81                  0.185251  \n",
              "82                 -0.266588  \n",
              "83                  0.038005  \n",
              "\n",
              "[84 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90ce0327-fdc2-4dfd-8139-80185ebd68fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_f0</th>\n",
              "      <th>avg_F1</th>\n",
              "      <th>avg_F2</th>\n",
              "      <th>avg_F3</th>\n",
              "      <th>avg_F4</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>jitter</th>\n",
              "      <th>shimmer</th>\n",
              "      <th>dispersion_formantique</th>\n",
              "      <th>avg_f0_k</th>\n",
              "      <th>mean_hnr_k</th>\n",
              "      <th>jitter_k</th>\n",
              "      <th>shimmer_k</th>\n",
              "      <th>dispersion_formantique_k</th>\n",
              "      <th>avg_f0_s</th>\n",
              "      <th>mean_hnr_s</th>\n",
              "      <th>jitter_s</th>\n",
              "      <th>shimmer_s</th>\n",
              "      <th>dispersion_formantique_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>304.75</td>\n",
              "      <td>778.00</td>\n",
              "      <td>2245.60</td>\n",
              "      <td>3571.05</td>\n",
              "      <td>5081.95</td>\n",
              "      <td>10.75</td>\n",
              "      <td>1.958567</td>\n",
              "      <td>1.377360</td>\n",
              "      <td>1434.650000</td>\n",
              "      <td>4.120596</td>\n",
              "      <td>6.512729</td>\n",
              "      <td>4.430703</td>\n",
              "      <td>2.066858</td>\n",
              "      <td>5.193159</td>\n",
              "      <td>1.026296</td>\n",
              "      <td>1.519206</td>\n",
              "      <td>1.205160</td>\n",
              "      <td>-0.259522</td>\n",
              "      <td>0.069057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>294.45</td>\n",
              "      <td>662.70</td>\n",
              "      <td>1939.90</td>\n",
              "      <td>3251.25</td>\n",
              "      <td>4775.30</td>\n",
              "      <td>12.25</td>\n",
              "      <td>1.663247</td>\n",
              "      <td>1.389308</td>\n",
              "      <td>1370.866667</td>\n",
              "      <td>2.278845</td>\n",
              "      <td>3.440682</td>\n",
              "      <td>3.091686</td>\n",
              "      <td>3.108758</td>\n",
              "      <td>2.927942</td>\n",
              "      <td>0.133170</td>\n",
              "      <td>0.667077</td>\n",
              "      <td>0.560049</td>\n",
              "      <td>-0.244830</td>\n",
              "      <td>-0.390032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>255.85</td>\n",
              "      <td>884.55</td>\n",
              "      <td>2183.50</td>\n",
              "      <td>3513.75</td>\n",
              "      <td>5111.40</td>\n",
              "      <td>12.90</td>\n",
              "      <td>1.422039</td>\n",
              "      <td>1.185426</td>\n",
              "      <td>1408.950000</td>\n",
              "      <td>1.737850</td>\n",
              "      <td>5.391922</td>\n",
              "      <td>2.999970</td>\n",
              "      <td>3.019235</td>\n",
              "      <td>2.481138</td>\n",
              "      <td>0.169958</td>\n",
              "      <td>1.548892</td>\n",
              "      <td>0.722608</td>\n",
              "      <td>-0.348192</td>\n",
              "      <td>0.175821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>292.75</td>\n",
              "      <td>652.05</td>\n",
              "      <td>2022.60</td>\n",
              "      <td>3177.75</td>\n",
              "      <td>4634.10</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.729150</td>\n",
              "      <td>1.645441</td>\n",
              "      <td>1327.350000</td>\n",
              "      <td>8.688811</td>\n",
              "      <td>2.620909</td>\n",
              "      <td>2.320086</td>\n",
              "      <td>2.652073</td>\n",
              "      <td>2.249446</td>\n",
              "      <td>-2.098723</td>\n",
              "      <td>-0.134290</td>\n",
              "      <td>0.045519</td>\n",
              "      <td>0.452664</td>\n",
              "      <td>0.225971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>305.75</td>\n",
              "      <td>739.75</td>\n",
              "      <td>2294.25</td>\n",
              "      <td>3706.60</td>\n",
              "      <td>4807.55</td>\n",
              "      <td>8.30</td>\n",
              "      <td>2.033454</td>\n",
              "      <td>1.544171</td>\n",
              "      <td>1355.933333</td>\n",
              "      <td>3.761873</td>\n",
              "      <td>3.485672</td>\n",
              "      <td>3.841500</td>\n",
              "      <td>7.036189</td>\n",
              "      <td>3.318189</td>\n",
              "      <td>0.993320</td>\n",
              "      <td>0.670789</td>\n",
              "      <td>1.151768</td>\n",
              "      <td>-1.606129</td>\n",
              "      <td>-0.338201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>272.40</td>\n",
              "      <td>1048.20</td>\n",
              "      <td>2396.10</td>\n",
              "      <td>3607.90</td>\n",
              "      <td>4777.30</td>\n",
              "      <td>8.65</td>\n",
              "      <td>1.148303</td>\n",
              "      <td>1.353881</td>\n",
              "      <td>1243.033333</td>\n",
              "      <td>2.016973</td>\n",
              "      <td>2.138940</td>\n",
              "      <td>2.361210</td>\n",
              "      <td>3.209799</td>\n",
              "      <td>2.195920</td>\n",
              "      <td>-0.675089</td>\n",
              "      <td>-0.074399</td>\n",
              "      <td>0.689445</td>\n",
              "      <td>-0.774658</td>\n",
              "      <td>-0.183286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>301.10</td>\n",
              "      <td>782.05</td>\n",
              "      <td>2184.90</td>\n",
              "      <td>3415.10</td>\n",
              "      <td>4666.85</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1.254625</td>\n",
              "      <td>0.952392</td>\n",
              "      <td>1294.933333</td>\n",
              "      <td>11.621063</td>\n",
              "      <td>2.995300</td>\n",
              "      <td>2.293056</td>\n",
              "      <td>2.490964</td>\n",
              "      <td>2.263339</td>\n",
              "      <td>-2.734114</td>\n",
              "      <td>-0.011581</td>\n",
              "      <td>0.444379</td>\n",
              "      <td>0.013398</td>\n",
              "      <td>-0.097667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>286.40</td>\n",
              "      <td>771.40</td>\n",
              "      <td>2272.80</td>\n",
              "      <td>3570.15</td>\n",
              "      <td>5088.50</td>\n",
              "      <td>10.35</td>\n",
              "      <td>1.583144</td>\n",
              "      <td>1.138822</td>\n",
              "      <td>1439.033333</td>\n",
              "      <td>1.879826</td>\n",
              "      <td>4.383631</td>\n",
              "      <td>8.614788</td>\n",
              "      <td>2.707580</td>\n",
              "      <td>1.990779</td>\n",
              "      <td>-0.242029</td>\n",
              "      <td>1.170294</td>\n",
              "      <td>2.336884</td>\n",
              "      <td>0.309732</td>\n",
              "      <td>0.185251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>261.35</td>\n",
              "      <td>682.65</td>\n",
              "      <td>2352.25</td>\n",
              "      <td>3547.65</td>\n",
              "      <td>5095.75</td>\n",
              "      <td>12.10</td>\n",
              "      <td>1.463657</td>\n",
              "      <td>1.052067</td>\n",
              "      <td>1471.033333</td>\n",
              "      <td>2.322844</td>\n",
              "      <td>1.838558</td>\n",
              "      <td>2.875774</td>\n",
              "      <td>1.973561</td>\n",
              "      <td>2.330892</td>\n",
              "      <td>0.462941</td>\n",
              "      <td>0.378098</td>\n",
              "      <td>0.655235</td>\n",
              "      <td>0.279183</td>\n",
              "      <td>-0.266588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>238.55</td>\n",
              "      <td>1020.15</td>\n",
              "      <td>2396.90</td>\n",
              "      <td>3565.35</td>\n",
              "      <td>4919.50</td>\n",
              "      <td>8.90</td>\n",
              "      <td>1.346442</td>\n",
              "      <td>1.266389</td>\n",
              "      <td>1299.783333</td>\n",
              "      <td>4.507005</td>\n",
              "      <td>2.386358</td>\n",
              "      <td>7.583330</td>\n",
              "      <td>2.475709</td>\n",
              "      <td>1.914359</td>\n",
              "      <td>-1.598119</td>\n",
              "      <td>0.170505</td>\n",
              "      <td>2.139388</td>\n",
              "      <td>0.003517</td>\n",
              "      <td>0.038005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90ce0327-fdc2-4dfd-8139-80185ebd68fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90ce0327-fdc2-4dfd-8139-80185ebd68fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90ce0327-fdc2-4dfd-8139-80185ebd68fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6ee328e-0d0a-407b-a7bc-57e29723c444\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6ee328e-0d0a-407b-a7bc-57e29723c444')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6ee328e-0d0a-407b-a7bc-57e29723c444 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31a0526d-d55f-426c-a322-8c348e2c9022\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31a0526d-d55f-426c-a322-8c348e2c9022 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 84,\n  \"fields\": [\n    {\n      \"column\": \"avg_f0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.93528100367362,\n        \"min\": 135.35,\n        \"max\": 350.85,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          294.0,\n          304.75,\n          309.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140.3576334301769,\n        \"min\": 568.1,\n        \"max\": 1265.75,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          1059.05,\n          778.0,\n          988.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 137.49529674321965,\n        \"min\": 1938.95,\n        \"max\": 2633.3,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2230.45,\n          2245.6,\n          2208.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146.69919028677222,\n        \"min\": 3177.75,\n        \"max\": 3970.9,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          3347.85,\n          3571.05,\n          3485.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_F4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.29389461186318,\n        \"min\": 4581.1,\n        \"max\": 5302.25,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          5033.95,\n          5081.95,\n          5029.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3361199909599972,\n        \"min\": 4.9,\n        \"max\": 16.55,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          4.9,\n          10.75,\n          11.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4169873261634001,\n        \"min\": 0.735873708,\n        \"max\": 3.024994612,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.991100056,\n          1.95856664,\n          1.028821193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20425923839610602,\n        \"min\": 0.816624405,\n        \"max\": 1.842686333,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1.020546757,\n          1.377359646,\n          0.928831882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.81632459238096,\n        \"min\": 1159.033333,\n        \"max\": 1506.983333,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1416.383333,\n          1434.65,\n          1403.416667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.149139715121006,\n        \"min\": 1.502538523,\n        \"max\": 14.22461757,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          5.830436913,\n          4.12059635,\n          2.619929051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0113270482798784,\n        \"min\": 1.636628881,\n        \"max\": 6.520670194,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2.932875765,\n          6.512729092,\n          2.67471935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.384573981241517,\n        \"min\": 1.708948397,\n        \"max\": 12.78754799,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          4.582699122,\n          4.430703242,\n          3.964456781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2824950760353502,\n        \"min\": 1.834133086,\n        \"max\": 9.666449675,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          2.834775216,\n          2.066857991,\n          2.495128841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.684444398329073,\n        \"min\": 1.632534979,\n        \"max\": 5.19315907,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          3.038196117,\n          5.19315907,\n          2.257816636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_f0_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0098806312022794,\n        \"min\": -2.734113835,\n        \"max\": 3.425743983,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          -1.328045265,\n          1.026296327,\n          0.157130814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_hnr_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5344824448074714,\n        \"min\": -0.622791378,\n        \"max\": 1.761441582,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.148278373,\n          1.519205733,\n          -0.466922287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jitter_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7472394249204369,\n        \"min\": -0.439475583,\n        \"max\": 3.104094568,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          1.352627409,\n          1.205159556,\n          0.980843827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shimmer_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6551324634987853,\n        \"min\": -1.606129365,\n        \"max\": 2.336159712,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.308434341,\n          -0.259522013,\n          -0.163107758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dispersion_formantique_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5029627591740098,\n        \"min\": -1.157513779,\n        \"max\": 1.126439929,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          -1.128668719,\n          0.069056976,\n          0.195156412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: The scikit-learn developers\n",
        "# SPDX-License-Identifier: BSD-3-Clause\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        (\"rfe\", RFE(estimator=LogisticRegression(), n_features_to_select=4, step=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipe.fit(X, y)\n",
        "\n",
        "print(\"First 4 best features: \", pipe.get_feature_names_out())\n",
        "\n",
        "ranking = pipe.named_steps[\"rfe\"].ranking_\n",
        "ranking = ranking.reshape(1, -1)\n",
        "\n",
        "# Plot pixel ranking\n",
        "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
        "\n",
        "# Add annotations for pixel numbers\n",
        "for i in range(ranking.shape[0]):\n",
        "    for j in range(ranking.shape[1]):\n",
        "        plt.text(j, i, str(ranking[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
        "\n",
        "plt.colorbar()\n",
        "plt.title(\"Ranking of features with RFE\\n(Logistic Regression)\")\n",
        "plt.show()\n",
        "\n",
        "print('\\ny: ' , len(y))\n",
        "print('\\nX: ', len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "72qjugSHPT36",
        "outputId": "9ff0414a-47ab-4a2c-d9b4-7915e2373fbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 4 best features:  ['avg_F1' 'jitter' 'shimmer' 'jitter_s']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "y:  84\n",
            "\n",
            "X:  84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "my = np.array(np.arange(0.62, 1.1, 0.15))\n",
        "mx = np.array([4]*(len(my)))\n",
        "plt.plot(mx,my,c='red', linestyle='--')\n",
        "plt.ylabel('Cummulative explained variance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8zgnuvQ7J7C9",
        "outputId": "9bf0af02-7dc7-46f2-bc86-c9306d4c95c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca.n_components = 4\n",
        "X = pca.fit_transform(X)\n",
        "print(\"Explained Variance Ratio: \", sum(pca.explained_variance_ratio_))\n",
        "display(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b786bb7d-257a-4530-f5a3-066edbd96d5c",
        "id": "xMcnZy-KWTB_"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio:  0.9890077247677216\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
        "from scipy.stats import mode\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, silhouette_score\n",
        "\n",
        "# Initialize StratifiedShuffleSplit Cross-Validation\n",
        "strat_shuffle_split = StratifiedShuffleSplit(n_splits=50, train_size=0.7, test_size=0.3)\n",
        "\n",
        "# Store ROC values, scores and thresholds for averaging\n",
        "tprs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "thresholds=[]\n",
        "accuracy_scores = []\n",
        "\n",
        "# Store confusion matrices\n",
        "conf_matrices = []\n",
        "optimalthreshold = 0.8\n",
        "kmeans = KMeans(n_clusters=2, init=\"k-means++\", n_init=10)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(strat_shuffle_split.split(X, y)):\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index] # Use indices to split X data\n",
        "    y_train, y_test = y[train_index], y[test_index] # Use indices to split y data\n",
        "\n",
        "    print(\"******************************\")\n",
        "\n",
        "    # Apply K-Means++ Clustering\n",
        "    kmeans.fit_transform(X_train)\n",
        "    cluster_labels = kmeans.fit_predict(X_train)\n",
        "\n",
        "    # Map Cluster Labels to Ground Truth Labels\n",
        "    # Ensure that mapping creates at least two unique labels\n",
        "    # Check the distribution of y_train within each cluster to determine the appropriate mapping\n",
        "    mapping = {}\n",
        "    for j in np.unique(cluster_labels):\n",
        "      # Get the most frequent ground truth label within the cluster\n",
        "      most_frequent_label = mode(y_train[cluster_labels == j], keepdims=True).mode[0]\n",
        "\n",
        "      # If the most frequent label is already in the mapping and it's the same as the current cluster\n",
        "      #  then assign a different label to ensure at least two unique labels\n",
        "      if most_frequent_label in mapping.values() and list(mapping.keys())[list(mapping.values()).index(most_frequent_label)] != j:\n",
        "        # Assign the opposite label (1 if most frequent is 0, and vice versa)\n",
        "        mapping[j] = 1 - most_frequent_label\n",
        "      else:\n",
        "        mapping[j] = most_frequent_label\n",
        "\n",
        "    mapped_preds = np.vectorize(mapping.get)(kmeans.predict(X_test))\n",
        "\n",
        "    # Ensure mapped_preds and y_test only contain 0 and 1\n",
        "    #This will force the labels to be binary\n",
        "    mapped_preds = np.where(mapped_preds > 1, 1, mapped_preds)\n",
        "    y_test = np.where(y_test > 1, 1, y_test)\n",
        "\n",
        "    #Display fold performance results\n",
        "    print(f\"Fold {i+1}: \\n\")\n",
        "    print(\"\\nCluster Labels: \\n\", cluster_labels)\n",
        "    print(\"\\nKMeans++ Score: \\n\", kmeans.score(X_test))\n",
        "    print(\"\\nMapping predictions: \\n\", mapped_preds)\n",
        "    print(\"\\nGround Truth: \\n\", y_test)\n",
        "    accuracy_score = np.mean(mapped_preds == y_test)\n",
        "    accuracy_scores.append(accuracy_score)\n",
        "    print(\"\\nAccuracy Score: \", accuracy_score)\n",
        "    print(\"\\nClassification Report: \\n\", classification_report(y_test, mapped_preds))\n",
        "    current_silhouette_score = silhouette_score(X_test, mapped_preds) # Change variable name to avoid overwriting the function\n",
        "    print(\"\\nSilhouette Score: \", current_silhouette_score)\n",
        "\n",
        "    # Compute ROC Curve\n",
        "    fpr, tpr, thresholds_kmeans = roc_curve(y_test, mapped_preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"\\nROC_AUC: \", roc_auc, \"\\n\")\n",
        "\n",
        "    # Interpolate tpr to have the same length as mean_fpr\n",
        "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
        "    interp_tpr[0] = 0.0  # Ensure the curve starts at (0, 0)\n",
        "    tprs.append(interp_tpr)\n",
        "\n",
        "    # Store best threshold (Youdenâ€™s J statistic)\n",
        "    j_scores = tpr - fpr  # Maximizing (TPR - FPR)\n",
        "    best_threshold = thresholds_kmeans[np.argmax(j_scores)]\n",
        "    thresholds.append(best_threshold)\n",
        "\n",
        "    # Applying  Decision Function Using Optimal Threshold\n",
        "    # Compute Distance to Cluster Centroids\n",
        "    distances = kmeans.transform(X_test)  # Distance to each centroid for test data\n",
        "    min_distances = np.min(distances, axis=1)  # Min distance to closest cluster\n",
        "\n",
        "    # Apply Threshold-Based Decision Rule\n",
        "    predicted_classes = (min_distances > optimalthreshold).astype(int)  # 1 if close, 0 if far\n",
        "\n",
        "    # Compute Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, mapped_preds)\n",
        "\n",
        "    # Ensure confusion matrix is always 2x2\n",
        "    if cm.shape != (2, 2):\n",
        "        cm_padded = np.zeros((2, 2), dtype=int)\n",
        "        cm_padded[:cm.shape[0], :cm.shape[1]] = cm\n",
        "        cm = cm_padded\n",
        "\n",
        "    conf_matrices.append(cm)\n",
        "    print(\"\\nConfusion Matrix: \\n\", cm)\n",
        "    print(\"\\n******************************\\n\")\n",
        "\n",
        "# Compute Mean ROC Curve\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "best_accuracy_index = np.argmax(accuracy_scores)\n",
        "best_accuracy = accuracy_scores[best_accuracy_index]\n",
        "print(\"Mean accuracy score: \", mean_accuracy)\n",
        "print(\"Best accuracy score: \", best_accuracy)\n",
        "\n",
        "# Compute Average Confusion Matrix\n",
        "avg_conf_matrix = np.mean(conf_matrices, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrlc6EN_AlAq",
        "outputId": "d734b718-7f0b-42d3-839a-0e60c1722a03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Cluster Labels: \n",
            " [1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1416927.9931283973\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50        12\n",
            "           1       0.57      0.57      0.57        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2966914684230738\n",
            "\n",
            "ROC_AUC:  0.5357142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 280: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2117888.631674024\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.7307692307692307\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.58      0.67        12\n",
            "           1       0.71      0.86      0.77        14\n",
            "\n",
            "    accuracy                           0.73        26\n",
            "   macro avg       0.74      0.72      0.72        26\n",
            "weighted avg       0.74      0.73      0.72        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2969640272043476\n",
            "\n",
            "ROC_AUC:  0.7202380952380952 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 2 12]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 281: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1285068.5442775765\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26007669882331597\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 282: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1863761.2927419613\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.50      0.46        12\n",
            "           1       0.50      0.43      0.46        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.35456783539952813\n",
            "\n",
            "ROC_AUC:  0.4642857142857143 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 283: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1699723.1912308019\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.17      0.22        12\n",
            "           1       0.50      0.71      0.59        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.42      0.44      0.41        26\n",
            "weighted avg       0.42      0.46      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.1837255580517501\n",
            "\n",
            "ROC_AUC:  0.44047619047619047 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 2 10]\n",
            " [ 4 10]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 284: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1314574.9869217644\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.3076923076923077\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.42      0.36        12\n",
            "           1       0.30      0.21      0.25        14\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.31      0.32      0.30        26\n",
            "weighted avg       0.31      0.31      0.30        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2181548659400072\n",
            "\n",
            "ROC_AUC:  0.3154761904761904 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 5  7]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 285: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0\n",
            " 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1694977.3287957956\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.3076923076923077\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.25      0.25        12\n",
            "           1       0.36      0.36      0.36        14\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.30      0.30      0.30        26\n",
            "weighted avg       0.31      0.31      0.31        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24242337991300172\n",
            "\n",
            "ROC_AUC:  0.3035714285714286 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 286: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1553646.4690057174\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.92      0.65        12\n",
            "           1       0.75      0.21      0.33        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.62      0.57      0.49        26\n",
            "weighted avg       0.63      0.54      0.48        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.1877685595817913\n",
            "\n",
            "ROC_AUC:  0.5654761904761904 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[11  1]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 287: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1471044.2110657229\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.52        12\n",
            "           1       0.60      0.64      0.62        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.57      0.57      0.57        26\n",
            "weighted avg       0.57      0.58      0.58        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24998862104714906\n",
            "\n",
            "ROC_AUC:  0.5714285714285714 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 288: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0\n",
            " 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1299719.9768004008\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.33      0.36        12\n",
            "           1       0.50      0.57      0.53        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.45      0.45      0.45        26\n",
            "weighted avg       0.45      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.22955643568910178\n",
            "\n",
            "ROC_AUC:  0.4523809523809524 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 289: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1910193.8838108962\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.83      0.65        12\n",
            "           1       0.71      0.36      0.48        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.62      0.60      0.56        26\n",
            "weighted avg       0.63      0.58      0.55        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24208309575286244\n",
            "\n",
            "ROC_AUC:  0.5952380952380953 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[10  2]\n",
            " [ 9  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 290: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1694485.48542037\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.42      0.42        12\n",
            "           1       0.50      0.50      0.50        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.46      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26081269906146326\n",
            "\n",
            "ROC_AUC:  0.45833333333333337 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 291: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1319431.6685281857\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.67      0.52        12\n",
            "           1       0.43      0.21      0.29        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.44      0.40        26\n",
            "weighted avg       0.43      0.42      0.39        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24918274525083\n",
            "\n",
            "ROC_AUC:  0.44047619047619047 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 8  4]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 292: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1448387.2303454012\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.75      0.56        12\n",
            "           1       0.50      0.21      0.30        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.47      0.48      0.43        26\n",
            "weighted avg       0.48      0.46      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.18987921280022507\n",
            "\n",
            "ROC_AUC:  0.4821428571428571 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 9  3]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 293: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1362917.7026890677\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.42      0.38        12\n",
            "           1       0.42      0.36      0.38        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.39      0.39      0.38        26\n",
            "weighted avg       0.39      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26704070595226026\n",
            "\n",
            "ROC_AUC:  0.3869047619047619 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 294: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1318271.20648622\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.33      0.32        12\n",
            "           1       0.38      0.36      0.37        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.35      0.35      0.35        26\n",
            "weighted avg       0.35      0.35      0.35        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2680488612703905\n",
            "\n",
            "ROC_AUC:  0.34523809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 295: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1621687.9994189257\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.33      0.36        12\n",
            "           1       0.50      0.57      0.53        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.45      0.45      0.45        26\n",
            "weighted avg       0.45      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27997303124148853\n",
            "\n",
            "ROC_AUC:  0.4523809523809524 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 296: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
            " 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2490236.5853216187\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.23076923076923078\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.50      0.38        12\n",
            "           1       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.23        26\n",
            "   macro avg       0.15      0.25      0.19        26\n",
            "weighted avg       0.14      0.23      0.17        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.19830091345073964\n",
            "\n",
            "ROC_AUC:  0.25 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [14  0]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 297: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1637458.1026899952\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      1.00      0.65        12\n",
            "           1       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.74      0.54      0.39        26\n",
            "weighted avg       0.76      0.50      0.37        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.16063818877768116\n",
            "\n",
            "ROC_AUC:  0.5357142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[12  0]\n",
            " [13  1]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 298: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1510677.9949424672\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61        12\n",
            "           1       0.67      0.71      0.69        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.65      0.65      0.65        26\n",
            "weighted avg       0.65      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3570850428751871\n",
            "\n",
            "ROC_AUC:  0.6488095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 4 10]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 299: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1354758.7088361206\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.67      0.62        12\n",
            "           1       0.67      0.57      0.62        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.62      0.62      0.62        26\n",
            "weighted avg       0.62      0.62      0.62        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2462828862480849\n",
            "\n",
            "ROC_AUC:  0.6190476190476191 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[8 4]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 300: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1277925.4461128572\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.42      0.48        12\n",
            "           1       0.59      0.71      0.65        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.57      0.57      0.56        26\n",
            "weighted avg       0.57      0.58      0.57        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.28921348390672025\n",
            "\n",
            "ROC_AUC:  0.5654761904761905 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 5  7]\n",
            " [ 4 10]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 301: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1621759.2616601053\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2986374572198468\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 302: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1940956.17690129\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.42      0.38        12\n",
            "           1       0.42      0.36      0.38        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.39      0.39      0.38        26\n",
            "weighted avg       0.39      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.28554557738854824\n",
            "\n",
            "ROC_AUC:  0.3869047619047619 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 303: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
            " 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1445648.3288476288\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.58      0.50        12\n",
            "           1       0.50      0.36      0.42        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.47      0.47      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.33366730017109325\n",
            "\n",
            "ROC_AUC:  0.47023809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 304: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1534060.9755745574\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.33      0.38        12\n",
            "           1       0.53      0.64      0.58        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.48        26\n",
            "weighted avg       0.49      0.50      0.49        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2675416621840676\n",
            "\n",
            "ROC_AUC:  0.48809523809523814 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 305: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1538972.0789602206\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.25      0.26        12\n",
            "           1       0.40      0.43      0.41        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.34      0.34      0.34        26\n",
            "weighted avg       0.34      0.35      0.34        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25395684762412774\n",
            "\n",
            "ROC_AUC:  0.3392857142857143 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 306: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1449968.812421932\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.7692307692307693\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.75      0.75        12\n",
            "           1       0.79      0.79      0.79        14\n",
            "\n",
            "    accuracy                           0.77        26\n",
            "   macro avg       0.77      0.77      0.77        26\n",
            "weighted avg       0.77      0.77      0.77        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.35423801303765123\n",
            "\n",
            "ROC_AUC:  0.7678571428571428 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 9  3]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 307: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1067164.318165899\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2748389984359096\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 308: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0\n",
            " 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1719395.0547536314\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.23307869389857488\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 309: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2012678.1960119759\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.58      0.52        12\n",
            "           1       0.55      0.43      0.48        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.51      0.51      0.50        26\n",
            "weighted avg       0.51      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24814571953997905\n",
            "\n",
            "ROC_AUC:  0.5059523809523809 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 310: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1907389.4921416324\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.50      0.46        12\n",
            "           1       0.50      0.43      0.46        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26559439131487267\n",
            "\n",
            "ROC_AUC:  0.4642857142857143 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 311: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1329934.8825315458\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.23752589399868332\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 312: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1280707.8811030523\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27043391294366426\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 313: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1675133.4922636193\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.27        12\n",
            "           1       0.44      0.50      0.47        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.37      0.38      0.37        26\n",
            "weighted avg       0.37      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3526006222105125\n",
            "\n",
            "ROC_AUC:  0.375 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 314: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1497245.680795889\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.33      0.35        12\n",
            "           1       0.47      0.50      0.48        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.42      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3128009854099175\n",
            "\n",
            "ROC_AUC:  0.41666666666666663 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 315: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1\n",
            " 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1538938.6702265758\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.50      0.46        12\n",
            "           1       0.50      0.43      0.46        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3275178638460493\n",
            "\n",
            "ROC_AUC:  0.4642857142857143 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 316: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1316675.2024073293\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.58      0.50        12\n",
            "           1       0.50      0.36      0.42        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.47      0.47      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2514729069805902\n",
            "\n",
            "ROC_AUC:  0.47023809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 317: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0\n",
            " 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2070923.7689703957\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.7307692307692307\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.58      0.67        12\n",
            "           1       0.71      0.86      0.77        14\n",
            "\n",
            "    accuracy                           0.73        26\n",
            "   macro avg       0.74      0.72      0.72        26\n",
            "weighted avg       0.74      0.73      0.72        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.29776987956817946\n",
            "\n",
            "ROC_AUC:  0.7202380952380952 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 2 12]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 318: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1743546.1243198402\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.50      0.43        12\n",
            "           1       0.40      0.29      0.33        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.39      0.39      0.38        26\n",
            "weighted avg       0.39      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.15329340358638402\n",
            "\n",
            "ROC_AUC:  0.3928571428571428 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 319: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1636413.7791515067\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.50      0.57        12\n",
            "           1       0.65      0.79      0.71        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.66      0.64      0.64        26\n",
            "weighted avg       0.66      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24451542564972578\n",
            "\n",
            "ROC_AUC:  0.6428571428571428 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 320: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1606092.6856319658\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.52        12\n",
            "           1       0.60      0.64      0.62        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.57      0.57      0.57        26\n",
            "weighted avg       0.57      0.58      0.58        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27612680484769936\n",
            "\n",
            "ROC_AUC:  0.5714285714285714 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 321: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1\n",
            " 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1644213.326689142\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24712664639467444\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 322: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1791402.3003336322\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.33109393951464106\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 323: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1681421.2015948724\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.258012464191521\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 324: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1328676.5464131953\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50        12\n",
            "           1       0.57      0.57      0.57        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27133827677963834\n",
            "\n",
            "ROC_AUC:  0.5357142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 325: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1673062.2810281601\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.33      0.35        12\n",
            "           1       0.47      0.50      0.48        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.42      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.17223203027707004\n",
            "\n",
            "ROC_AUC:  0.41666666666666663 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 326: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1796790.951287833\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26160836677739485\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 327: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1393706.4874265017\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.58      0.58        12\n",
            "           1       0.64      0.64      0.64        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.61      0.61      0.61        26\n",
            "weighted avg       0.62      0.62      0.62        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.21796303090301697\n",
            "\n",
            "ROC_AUC:  0.613095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 328: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1857405.8052486023\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.92      0.67        12\n",
            "           1       0.80      0.29      0.42        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.66      0.60      0.54        26\n",
            "weighted avg       0.67      0.58      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.18983241077489518\n",
            "\n",
            "ROC_AUC:  0.601190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[11  1]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 329: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1129123.0839612035\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25778287323986426\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 330: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1414570.5601206461\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44        12\n",
            "           1       0.45      0.36      0.40        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.43      0.43      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2942352709676456\n",
            "\n",
            "ROC_AUC:  0.4285714285714286 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 331: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1\n",
            " 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1413824.317451698\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.92      0.67        12\n",
            "           1       0.80      0.29      0.42        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.66      0.60      0.54        26\n",
            "weighted avg       0.67      0.58      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25364623253506857\n",
            "\n",
            "ROC_AUC:  0.601190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[11  1]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 332: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1463663.334626793\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.19410382093648737\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 333: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1559353.9580567142\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.27        12\n",
            "           1       0.44      0.50      0.47        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.37      0.38      0.37        26\n",
            "weighted avg       0.37      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.20095544767281898\n",
            "\n",
            "ROC_AUC:  0.375 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 334: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0\n",
            " 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1676564.881797219\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61        12\n",
            "           1       0.67      0.71      0.69        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.65      0.65      0.65        26\n",
            "weighted avg       0.65      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25614914240439046\n",
            "\n",
            "ROC_AUC:  0.6488095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 4 10]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 335: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1469895.2270139696\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.58      0.54        12\n",
            "           1       0.58      0.50      0.54        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.21551653486974345\n",
            "\n",
            "ROC_AUC:  0.5416666666666666 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 336: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1488553.3572307345\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.7307692307692307\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.67      0.70        12\n",
            "           1       0.73      0.79      0.76        14\n",
            "\n",
            "    accuracy                           0.73        26\n",
            "   macro avg       0.73      0.73      0.73        26\n",
            "weighted avg       0.73      0.73      0.73        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3440859500492615\n",
            "\n",
            "ROC_AUC:  0.7261904761904762 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 8  4]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 337: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1417233.1558669622\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26347201078314186\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 338: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1288158.3718690798\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2719461293443017\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 339: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1904290.354659899\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.33      0.32        12\n",
            "           1       0.38      0.36      0.37        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.35      0.35      0.35        26\n",
            "weighted avg       0.35      0.35      0.35        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.28326705857709755\n",
            "\n",
            "ROC_AUC:  0.34523809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 340: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2166901.8371596606\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.2692307692307692\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.33      0.30        12\n",
            "           1       0.27      0.21      0.24        14\n",
            "\n",
            "    accuracy                           0.27        26\n",
            "   macro avg       0.27      0.27      0.27        26\n",
            "weighted avg       0.27      0.27      0.27        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3065576592004081\n",
            "\n",
            "ROC_AUC:  0.27380952380952384 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 4  8]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 341: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1699103.858142104\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24329270566439462\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 342: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1198294.9158395112\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.67      0.62        12\n",
            "           1       0.67      0.57      0.62        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.62      0.62      0.62        26\n",
            "weighted avg       0.62      0.62      0.62        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.31235469084501016\n",
            "\n",
            "ROC_AUC:  0.6190476190476191 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[8 4]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 343: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1534754.0216517367\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.92      0.63        12\n",
            "           1       0.67      0.14      0.24        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.57      0.53      0.43        26\n",
            "weighted avg       0.58      0.50      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.18937060387845148\n",
            "\n",
            "ROC_AUC:  0.5297619047619047 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[11  1]\n",
            " [12  2]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 344: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1698490.3260474806\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.50      0.57        12\n",
            "           1       0.65      0.79      0.71        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.66      0.64      0.64        26\n",
            "weighted avg       0.66      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26902489609902536\n",
            "\n",
            "ROC_AUC:  0.6428571428571428 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 345: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1420894.5381475138\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.22337891259816403\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 346: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1721812.6776851378\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.23076923076923078\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.25      0.23        12\n",
            "           1       0.25      0.21      0.23        14\n",
            "\n",
            "    accuracy                           0.23        26\n",
            "   macro avg       0.23      0.23      0.23        26\n",
            "weighted avg       0.23      0.23      0.23        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.23668538927009333\n",
            "\n",
            "ROC_AUC:  0.23214285714285712 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 3  9]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 347: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1728889.6345397106\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.6923076923076923\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.58      0.64        12\n",
            "           1       0.69      0.79      0.73        14\n",
            "\n",
            "    accuracy                           0.69        26\n",
            "   macro avg       0.69      0.68      0.68        26\n",
            "weighted avg       0.69      0.69      0.69        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2604497321017728\n",
            "\n",
            "ROC_AUC:  0.6845238095238094 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 348: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1910538.2290835162\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.58      0.48        12\n",
            "           1       0.44      0.29      0.35        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.43      0.43      0.42        26\n",
            "weighted avg       0.43      0.42      0.41        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2861082322970756\n",
            "\n",
            "ROC_AUC:  0.4345238095238094 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 349: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1530813.3275103942\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.75      0.67        12\n",
            "           1       0.73      0.57      0.64        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.66      0.66      0.65        26\n",
            "weighted avg       0.67      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.265755560283082\n",
            "\n",
            "ROC_AUC:  0.6607142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[9 3]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 350: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1624902.094942371\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.27        12\n",
            "           1       0.44      0.50      0.47        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.37      0.38      0.37        26\n",
            "weighted avg       0.37      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2501123354933592\n",
            "\n",
            "ROC_AUC:  0.375 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 351: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0\n",
            " 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1998343.1013369088\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.58      0.50        12\n",
            "           1       0.50      0.36      0.42        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.47      0.47      0.46        26\n",
            "weighted avg       0.47      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.13084774957050743\n",
            "\n",
            "ROC_AUC:  0.47023809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 352: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1281107.6537999115\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.42      0.38        12\n",
            "           1       0.42      0.36      0.38        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.39      0.39      0.38        26\n",
            "weighted avg       0.39      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.30965568430652024\n",
            "\n",
            "ROC_AUC:  0.3869047619047619 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 353: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1677478.6720944154\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.58      0.56        12\n",
            "           1       0.62      0.57      0.59        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.58      0.58      0.58        26\n",
            "weighted avg       0.58      0.58      0.58        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24535903245177787\n",
            "\n",
            "ROC_AUC:  0.5773809523809523 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 354: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1426924.1616094583\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.42      0.37        12\n",
            "           1       0.36      0.29      0.32        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.35      0.35      0.35        26\n",
            "weighted avg       0.35      0.35      0.34        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.30220232670765745\n",
            "\n",
            "ROC_AUC:  0.3511904761904761 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 5  7]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 355: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1925393.3912161682\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44        12\n",
            "           1       0.45      0.36      0.40        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.43      0.43      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25140683051128315\n",
            "\n",
            "ROC_AUC:  0.4285714285714286 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 356: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1694277.2899733996\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.83      0.62        12\n",
            "           1       0.67      0.29      0.40        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.58      0.56      0.51        26\n",
            "weighted avg       0.59      0.54      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.15556388436718244\n",
            "\n",
            "ROC_AUC:  0.5595238095238095 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[10  2]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 357: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1637595.4839665913\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.83      0.65        12\n",
            "           1       0.71      0.36      0.48        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.62      0.60      0.56        26\n",
            "weighted avg       0.63      0.58      0.55        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.30324305073580304\n",
            "\n",
            "ROC_AUC:  0.5952380952380953 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[10  2]\n",
            " [ 9  5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 358: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1450512.2894539516\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.31641471596055665\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 359: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1459394.9894818831\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.42      0.42        12\n",
            "           1       0.50      0.50      0.50        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.46      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2218768951298742\n",
            "\n",
            "ROC_AUC:  0.45833333333333337 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 360: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1023680.8033913447\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61        12\n",
            "           1       0.67      0.71      0.69        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.65      0.65      0.65        26\n",
            "weighted avg       0.65      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.29712920287241257\n",
            "\n",
            "ROC_AUC:  0.6488095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 7  5]\n",
            " [ 4 10]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 361: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1831479.1274034285\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19        12\n",
            "           1       0.41      0.50      0.45        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.32      0.33      0.32        26\n",
            "weighted avg       0.32      0.35      0.33        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.282085008314368\n",
            "\n",
            "ROC_AUC:  0.3333333333333333 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 2 10]\n",
            " [ 7  7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 362: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1229490.7078983195\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27107260976096853\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 363: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1829203.1550646236\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.83      0.67        12\n",
            "           1       0.75      0.43      0.55        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.65      0.63      0.61        26\n",
            "weighted avg       0.66      0.62      0.60        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.22907832835986927\n",
            "\n",
            "ROC_AUC:  0.6309523809523809 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[10  2]\n",
            " [ 8  6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 364: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1688885.6898756109\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.2692307692307692\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.08      0.10        12\n",
            "           1       0.35      0.43      0.39        14\n",
            "\n",
            "    accuracy                           0.27        26\n",
            "   macro avg       0.23      0.26      0.24        26\n",
            "weighted avg       0.24      0.27      0.25        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2297565874967687\n",
            "\n",
            "ROC_AUC:  0.25595238095238093 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 1 11]\n",
            " [ 8  6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 365: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1993673.3533468796\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3324989027533334\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 366: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1794330.791301671\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50        12\n",
            "           1       0.57      0.57      0.57        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2762871782997797\n",
            "\n",
            "ROC_AUC:  0.5357142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 367: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1887598.9110477392\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2452453232286393\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 368: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1\n",
            " 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1782815.3553200031\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.6538461538461539\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.50      0.57        12\n",
            "           1       0.65      0.79      0.71        14\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.66      0.64      0.64        26\n",
            "weighted avg       0.66      0.65      0.65        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2938911009522842\n",
            "\n",
            "ROC_AUC:  0.6428571428571428 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 369: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1964105.1350398706\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.50      0.41        12\n",
            "           1       0.33      0.21      0.26        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.34      0.36      0.34        26\n",
            "weighted avg       0.34      0.35      0.33        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.31991408886112777\n",
            "\n",
            "ROC_AUC:  0.3571428571428571 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 6  6]\n",
            " [11  3]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 370: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1921017.275089741\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.31474900497261815\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 371: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -2372702.0154226753\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.34615384615384615\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.42      0.37        12\n",
            "           1       0.36      0.29      0.32        14\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.35      0.35      0.35        26\n",
            "weighted avg       0.35      0.35      0.34        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26589260635866724\n",
            "\n",
            "ROC_AUC:  0.3511904761904761 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 5  7]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 372: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1861099.4032849032\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50        12\n",
            "           1       0.57      0.57      0.57        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2471741307049397\n",
            "\n",
            "ROC_AUC:  0.5357142857142857 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 373: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1433472.6708813263\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26346701953664936\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 374: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1641764.2470757796\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.33      0.36        12\n",
            "           1       0.50      0.57      0.53        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.45      0.45      0.45        26\n",
            "weighted avg       0.45      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.15107409812190115\n",
            "\n",
            "ROC_AUC:  0.4523809523809524 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 375: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1294908.7300724557\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2637285206904583\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 376: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1506728.8572903725\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.250696949336675\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 377: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0\n",
            " 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1492380.8914776007\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.38461538461538464\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33        12\n",
            "           1       0.43      0.43      0.43        14\n",
            "\n",
            "    accuracy                           0.38        26\n",
            "   macro avg       0.38      0.38      0.38        26\n",
            "weighted avg       0.38      0.38      0.38        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.36764220622075927\n",
            "\n",
            "ROC_AUC:  0.380952380952381 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 378: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1711439.5537382106\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2852561272346411\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 379: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1281641.0705391488\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.25      0.30        12\n",
            "           1       0.50      0.64      0.56        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.44      0.45      0.43        26\n",
            "weighted avg       0.44      0.46      0.44        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24763733052671494\n",
            "\n",
            "ROC_AUC:  0.44642857142857145 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 380: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0\n",
            " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1504324.8294395544\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.67      0.57        12\n",
            "           1       0.60      0.43      0.50        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.55      0.55      0.54        26\n",
            "weighted avg       0.55      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2554601292003008\n",
            "\n",
            "ROC_AUC:  0.5476190476190477 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[8 4]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 381: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1232919.0090801327\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3192926223814425\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 382: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
            " 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1527672.489387321\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.58      0.54        12\n",
            "           1       0.58      0.50      0.54        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.54      0.54      0.54        26\n",
            "weighted avg       0.54      0.54      0.54        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2782181016244848\n",
            "\n",
            "ROC_AUC:  0.5416666666666666 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 383: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1345349.748232563\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40        12\n",
            "           1       0.46      0.43      0.44        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.42      0.42      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25393451799908423\n",
            "\n",
            "ROC_AUC:  0.4226190476190476 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 384: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1304003.8099811727\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.67      0.62        12\n",
            "           1       0.67      0.57      0.62        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.62      0.62      0.62        26\n",
            "weighted avg       0.62      0.62      0.62        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.22588718847411696\n",
            "\n",
            "ROC_AUC:  0.6190476190476191 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[8 4]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 385: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1560941.3628592573\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.17      0.24        12\n",
            "           1       0.52      0.79      0.63        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.46      0.48      0.43        26\n",
            "weighted avg       0.47      0.50      0.45        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.20423684212890783\n",
            "\n",
            "ROC_AUC:  0.47619047619047616 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 2 10]\n",
            " [ 3 11]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 386: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1488934.7047611184\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1]\n",
            "\n",
            "Accuracy Score:  0.6153846153846154\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.58      0.58        12\n",
            "           1       0.64      0.64      0.64        14\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.61      0.61      0.61        26\n",
            "weighted avg       0.62      0.62      0.62        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.22907528682846018\n",
            "\n",
            "ROC_AUC:  0.613095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 387: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0\n",
            " 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1604213.9220782085\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.5384615384615384\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.42      0.45        12\n",
            "           1       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.53      0.53      0.53        26\n",
            "weighted avg       0.53      0.54      0.53        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.20829317720840673\n",
            "\n",
            "ROC_AUC:  0.5297619047619048 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 388: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0\n",
            " 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1990434.602755013\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.43        12\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.49        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.34503658984657865\n",
            "\n",
            "ROC_AUC:  0.49404761904761896 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [6 8]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 389: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1793449.5263133226\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.19230769230769232\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.33      0.28        12\n",
            "           1       0.11      0.07      0.09        14\n",
            "\n",
            "    accuracy                           0.19        26\n",
            "   macro avg       0.17      0.20      0.18        26\n",
            "weighted avg       0.17      0.19      0.17        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2262789609680067\n",
            "\n",
            "ROC_AUC:  0.20238095238095238 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 4  8]\n",
            " [13  1]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 390: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1594353.5578779161\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.3076923076923077\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.33      0.31        12\n",
            "           1       0.33      0.29      0.31        14\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.31      0.31      0.31        26\n",
            "weighted avg       0.31      0.31      0.31        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.27945271580380365\n",
            "\n",
            "ROC_AUC:  0.30952380952380953 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 4  8]\n",
            " [10  4]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 391: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1603088.107029823\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.67      0.55        12\n",
            "           1       0.56      0.36      0.43        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.51      0.51      0.49        26\n",
            "weighted avg       0.52      0.50      0.49        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.24484563383007119\n",
            "\n",
            "ROC_AUC:  0.511904761904762 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[8 4]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 392: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1770458.7349509979\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2483511709217215\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 393: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1760182.355410895\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0]\n",
            "\n",
            "Accuracy Score:  0.5769230769230769\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.52        12\n",
            "           1       0.60      0.64      0.62        14\n",
            "\n",
            "    accuracy                           0.58        26\n",
            "   macro avg       0.57      0.57      0.57        26\n",
            "weighted avg       0.57      0.58      0.58        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.26249924927244883\n",
            "\n",
            "ROC_AUC:  0.5714285714285714 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 394: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1824383.938785855\n",
            "\n",
            "Mapping predictions: \n",
            " [1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.25079292567339734\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 395: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1810932.507637416\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.33      0.38        12\n",
            "           1       0.53      0.64      0.58        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.49      0.49      0.48        26\n",
            "weighted avg       0.49      0.50      0.49        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.251070264457423\n",
            "\n",
            "ROC_AUC:  0.48809523809523814 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[4 8]\n",
            " [5 9]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 396: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1247347.765309727\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1]\n",
            "\n",
            "Accuracy Score:  0.3076923076923077\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.25      0.25        12\n",
            "           1       0.36      0.36      0.36        14\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.30      0.30      0.30        26\n",
            "weighted avg       0.31      0.31      0.31        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.3069310002637933\n",
            "\n",
            "ROC_AUC:  0.3035714285714286 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3 9]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 397: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1539050.9313226265\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0]\n",
            "\n",
            "Accuracy Score:  0.4230769230769231\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44        12\n",
            "           1       0.45      0.36      0.40        14\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.43      0.43      0.42        26\n",
            "weighted avg       0.43      0.42      0.42        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.297788897194025\n",
            "\n",
            "ROC_AUC:  0.4285714285714286 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [9 5]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 398: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1396532.3510243234\n",
            "\n",
            "Mapping predictions: \n",
            " [0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.58      0.52        12\n",
            "           1       0.55      0.43      0.48        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.51      0.51      0.50        26\n",
            "weighted avg       0.51      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.292124730561637\n",
            "\n",
            "ROC_AUC:  0.5059523809523809 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[7 5]\n",
            " [8 6]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 399: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1334199.254139182\n",
            "\n",
            "Mapping predictions: \n",
            " [0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0]\n",
            "\n",
            "Ground Truth: \n",
            " [0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0]\n",
            "\n",
            "Accuracy Score:  0.46153846153846156\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.42      0.42        12\n",
            "           1       0.50      0.50      0.50        14\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.46      0.46      0.46        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2589095155414883\n",
            "\n",
            "ROC_AUC:  0.45833333333333337 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5 7]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "******************************\n",
            "Fold 400: \n",
            "\n",
            "\n",
            "Cluster Labels: \n",
            " [0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1]\n",
            "\n",
            "KMeans++ Score: \n",
            " -1456052.7222992233\n",
            "\n",
            "Mapping predictions: \n",
            " [1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0]\n",
            "\n",
            "Ground Truth: \n",
            " [1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0]\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.50      0.48        12\n",
            "           1       0.54      0.50      0.52        14\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.50      0.50      0.50        26\n",
            "weighted avg       0.50      0.50      0.50        26\n",
            "\n",
            "\n",
            "Silhouette Score:  0.2560846639735154\n",
            "\n",
            "ROC_AUC:  0.5 \n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[6 6]\n",
            " [7 7]]\n",
            "\n",
            "******************************\n",
            "\n",
            "Mean accuracy score:  0.49336538461538465\n",
            "Best accuracy score:  0.8076923076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "bced8ee8-0c45-4ec7-d785-7e12b855c33e",
        "id": "dmpHxMbB6bvC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.895  6.105 ]\n",
            " [7.0675 6.9325]]\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Displaying KMeans++ confusion matrix for\n",
        "#2 classes (Groups - ASD and CTRL) - (NO TD))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "c_cm = cm\n",
        "cm = avg_conf_matrix\n",
        "\n",
        "print(avg_conf_matrix)\n",
        "print(cm.shape[0])\n",
        "print(cm.shape[1])\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(x=j, y=i,s=cm[i, j], va='center',\n",
        "                ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Average Confusion Matrix Across Folds', fontsize=18)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilisation de SVC Cross-Validation (CV) avec ROC scoring.\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, classification_report, fowlkes_mallows_score, normalized_mutual_info_score, silhouette_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "rs = ShuffleSplit(n_splits=100, train_size=0.7, test_size=0.3, random_state=13)\n",
        "\n",
        "#Creation du SVC pour la classification\n",
        "model_SVC = SVC(kernel=\"linear\", probability=True, random_state=13)\n",
        "\n",
        "# Fit KMeans on the training data\n",
        "model_KMeans = KMeans(n_clusters=2, max_iter=50, init=\"k-means++\", random_state=13)\n",
        "clustered_labels = model_KMeans.fit_predict(X, y)\n",
        "\n",
        "#Evaluate clustering\n",
        "silhouette_avg = silhouette_score(X, clustered_labels)\n",
        "print(\"For model_KMeans: \\n\", model_KMeans.get_params(), \"\\nThe average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "# Split train/test (70%/30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, clustered_labels, test_size=0.3, random_state=0)\n",
        "\n",
        "# Apply Supervised KMeans classification on clustered training data and perform cross-validation.\n",
        "scores = cross_val_score(model_SVC, X_train, y_train, cv=rs, verbose=5, scoring='roc_auc')\n",
        "scores = scores[~np.isnan(scores)]\n",
        "print(\"\\nSVC classification with cross-validation score: \", np.mean(scores))\n",
        "\n",
        "#Display results\n",
        "y_pred = model_SVC.fit(X_train, y_train).predict(X_train)\n",
        "print(\"\\nAccuracy Score: \", accuracy_score(y_train, y_pred))\n",
        "print(\"\\nClassification Report: \\n\", classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORpVVPPO8IB3",
        "outputId": "9858917d-7932-48a3-a342-6695234ef7ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For model_KMeans: \n",
            " {'algorithm': 'lloyd', 'copy_x': True, 'init': 'k-means++', 'max_iter': 50, 'n_clusters': 2, 'n_init': 'auto', 'random_state': 13, 'tol': 0.0001, 'verbose': 0} \n",
            "The average silhouette_score is : 0.31086097104343385\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.938) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.987) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.978) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.948) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.985) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.982) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END .................................. score: (test=nan) total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.954) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.987) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.964) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.929) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.985) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.978) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "[CV] END ................................ score: (test=1.000) total time=   0.0s\n",
            "\n",
            "SVC classification with cross-validation score:  0.9961027468603226\n",
            "\n",
            "Accuracy Score:  1.0\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        43\n",
            "\n",
            "    accuracy                           1.00        58\n",
            "   macro avg       1.00      1.00      1.00        58\n",
            "weighted avg       1.00      1.00      1.00        58\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "fc5fcf48-bcfb-4ff4-bbe9-57b1a00b3cc0",
        "id": "oxASIkZ6UcMt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15  0]\n",
            " [ 0 43]]\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Displaying KMeans++ confusion matrix for\n",
        "#2 classes (Groups - ASD and CTRL) - (NO TD))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(cm)\n",
        "print(cm.shape[0])\n",
        "print(cm.shape[1])\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(x=j, y=i,s=cm[i, j], va='center',\n",
        "                ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Shuffle Plit SVC Confusion Matrix', fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "# Compute Average Confusion Matrix\n",
        "avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lDTkX_QMpOfBTMqZ4UlRvH7sAOTiNU9Y",
      "authorship_tag": "ABX9TyNsuGApK/JEWZVoLWViYQ3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}